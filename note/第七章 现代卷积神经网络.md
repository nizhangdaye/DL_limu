```toc
```

- 深度神经网络的概念非常简单——==将神经网络堆叠在一起==
- 本章介绍的神经网络
    - AlexNet：它是第一个在大规模视觉竞赛中击败传统计算机视觉模型的大型神经网络；
    - 使用重复块的网络（VGG）：它利用许多重复的神经网络块；
    - 网络中的网络（NiN）：它重复使用由卷积层和1×1卷积层（用来代替全连接层）来构建深层网络;
    - 含并行连结的网络（GoogLeNet）：它使用并行连结的网络，通过不同窗口大小的卷积层和最大汇聚层来并行抽取信息；
    - 残差网络（ResNet）：它通过残差块构建跨层的数据通道，是计算机视觉中最流行的体系架构；
    - 稠密连接网络（DenseNet）：它的计算成本很高，但给我们带来了更好的效果

## 深度卷积神经网络（AlexNet）

- 与传统机器学习的差别![[00 Attachments/Pasted image 20240607000848.png|400]]
    - 引入丢弃法（在全连接层之后）
        - 控制模型容量的大小
    - 激活函数从 LeNet 的 sigmoid 改为 ReLu
        - ReLu 的导数更加稳定（>0 为 1），可以支撑更深的模型（为什么？减缓了梯度消失）
    - 从 LeNet 的平均池化层改为了最大池化层
        - 最大池化层使输出更大，使得梯度更大，从而使训练更加容易
- AlexNet 不只只使得模型变得更大更深，更带来了观念得改变
    - 在神经网络之前，通常对图像进行人工得特征提取，主要关系怎么对特征进行提取
    - 而 AlexNet 可以通过 CNN 学习特征，使得抽取出来得特征（模式）能使 Softmax 做更好得分类
    - 相比人工特征提取更加简单，不用了解太多专业的知识（跨专业）

### AlexNet 架构

- 从 LeNet（左）到 AlexNet（右）![[00 Attachments/Pasted image 20240610231814.png]]
    - 在AlexNet的第一层，卷积窗口的形状是11×11
        - 由于ImageNet中大多数图像的宽和高比MNIST图像的多10倍以上，因此，需要一个更大的卷积窗口来捕获目标
    - 第二层中的卷积窗口形状被缩减为5×5，然后是3×3
    - 此外，在第一层、第二层和第五层卷积层之后，加入窗口形状为3×3、步幅为2的最大汇聚层
    - 而且，AlexNet的卷积通道数目是LeNet的10倍
    - 在最后一个卷积层后有两个全连接层，分别有4096个输出
        - 这两个巨大的全连接层拥有将近1GB的模型参数
- 其实就是一个更深的更大的 LeNet，能分更多的类![[00 Attachments/Pasted image 20240607003040.png|400]]
    - 第一层卷积层就输出了更多的通道：希望识别出更多的模式
- ![[00 Attachments/Pasted image 20240607003118.png|400]]
    - 通道从 96 到 256，相比 LeNet 增长的更大了：为了识别更多的输出模式（特征）
    - 之后先用三个卷积层（填充为 1（指左右上下各加一行或列），使输入输出一致），再通过池化层
- 通过三个全连接层![[00 Attachments/Pasted image 20240607003129.png|400]]

### 更多细节

- AlexNet 将 sigmoid 激活函数改为更简单的 ReLU 激活函数
    - 一方面，ReLU 激活函数的计算更简单，它不需要如 sigmoid 激活函数那般复杂的求幂运算
    - 另一方面，当使用不同的参数初始化方法时，ReLU 激活函数使训练模型更加容易。
        - 当 sigmoid 激活函数的输出非常接近于 0 或 1 时，这些区域的梯度几乎为 0，因此反向传播无法继续更新一些模型参数
        - 相反，ReLU 激活函数在正区间的梯度总是 1。
        - 因此，如果模型参数没有正确初始化，sigmoid 函数可能在正区间内得到几乎为 0 的梯度，从而使模型无法得到有效的训练
- ![[00 Attachments/Pasted image 20240607005141.png|400]]
    - ReLu 的一阶导为 1，相对于 sigmoid （输出远离零点时，导数很小，可能导致梯度消失）更加稳定
    - 通过实物图增加大量的变种（通过卷积核得到新图片，模拟各种变化），减弱神经网络记忆数据的能力（过拟合）
        - 多了更多的数据（但又不增加数据集），使神经网络脱敏
- 复杂度![[00 Attachments/Pasted image 20240607005152.png|400]]
    - 可学习的参数的个数上，AlexNet 比 LeNet 多了很多
    - 浮点计算消耗量更大了

### 总结

- AlexNet 是更大更深更胖的 LeNet，10× 参数个数，260× 计算复杂度
- 新加了丢弃法，ReLu，最大池化层，和数据增强

### 代码实现

#### AlexNet

- AlexNet 通过暂退法（[4.6节](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/dropout.html#sec-dropout)
  ）控制全连接层的模型复杂度，而 LeNet 只使用了权重衰减（在梯度下降中）
- 为了进一步扩充数据，AlexNet 在训练时增加了大量的图像增强数据，如翻转、裁切和变色（输出的通道变多了）
    - 这使得模型更健壮，更大的样本量有效地减少了过拟合
    - 在[13.1节](https://zh-v2.d2l.ai/chapter_computer-vision/image-augmentation.html#sec-image-augmentation)中更详细地讨论数据扩增

```python
import torch
from torch import nn
from d2l import torch as d2l

net = nn.Sequential(
    # 这里使用一个11*11的更大窗口来捕捉对象。
    # 同时，步幅为4，以减少输出的高度和宽度。
    # 另外，输出通道的数目远大于LeNet
    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数
    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    # 使用三个连续的卷积层和较小的卷积窗口。
    # 除了最后的卷积层，输出通道的数量进一步增加。
    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度
    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Flatten(),
    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合
    nn.Linear(6400, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(4096, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000
    nn.Linear(4096, 10))
```

- 构造一个高度和宽度都为 224 的单通道数据，来观察每一层输出的形状

```python
X = torch.randn(1, 1, 224, 224)
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__, 'Output shape:\t', X.shape)
# Conv2d output shape:         torch.Size([1, 96, 54, 54])  
# ReLU output shape:   torch.Size([1, 96, 54, 54])  
# MaxPool2d output shape:      torch.Size([1, 96, 26, 26])  
# Conv2d output shape:         torch.Size([1, 256, 26, 26])  
# ReLU output shape:   torch.Size([1, 256, 26, 26])  
# MaxPool2d output shape:      torch.Size([1, 256, 12, 12])  
# Conv2d output shape:         torch.Size([1, 384, 12, 12])  
# ReLU output shape:   torch.Size([1, 384, 12, 12])  
# Conv2d output shape:         torch.Size([1, 384, 12, 12])  
# ReLU output shape:   torch.Size([1, 384, 12, 12])  
# Conv2d output shape:         torch.Size([1, 256, 12, 12])  
# ReLU output shape:   torch.Size([1, 256, 12, 12])  
# MaxPool2d output shape:      torch.Size([1, 256, 5, 5])  
# Flatten output shape:        torch.Size([1, 6400])  
# Linear output shape:         torch.Size([1, 4096])  
# ReLU output shape:   torch.Size([1, 4096])  
# Dropout output shape:        torch.Size([1, 4096])  
# Linear output shape:         torch.Size([1, 4096])  
# ReLU output shape:   torch.Size([1, 4096])  
# Dropout output shape:        torch.Size([1, 4096])  
# Linear output shape:         torch.Size([1, 10])
```

#### 读取数据集

- 将 AlexNet 直接应用于 Fashion-MNIST 的一个问题是，Fashion-MNIST 图像的分辨率（ 28×28 像素）低于 ImageNet 图像
    - 为了解决这个问题，我们将它们增加到 224×224（通常来讲这不是一个明智的做法，但在这里这样做是为了有效使用 AlexNet 架构）
    - 这里需要使用`d2l.load_data_fashion_mnist`函数中的`resize`参数执行此调整

```python
batch_size = 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)
```

#### 训练 AlexNet

```python
lr, num_epochs = 0.01, 10
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
# loss 0.327, train acc 0.880, test acc 0.883
# 721.4 examples/sec on cuda:0
# 训练耗时：1194.266344秒
```

- ![[00 Attachments/Figure_9.png|400]]

## 使用块的网络（VGG）

- 从AlexNet到VGG，它们本质上都是块设计![[00 Attachments/Pasted image 20240611001213.png]]
- 虽然 AlexNet 证明深层神经网络卓有成效，但它没有提供一个通用的模板来指导后续的研究人员设计新的网络
    - AlexNet 似乎有点随意，结构不那么清晰，不能很好的指导模型如何变宽，变深
- 因此需要一个更好的设计思想（要有框架）
    - 如何更好的更深更大
- ![[00 Attachments/Pasted image 20240607012324.png|400]]
- 如何更好的更深更大![[00 Attachments/Pasted image 20240607012505.png|400]]
    - 全连接层参数太多
    - 又不能像 AlexNet 那样单纯的增加卷积层数（太麻烦）

### VGG 块

- 经典卷积神经网络的基本组成部分是下面的这个序列：
    1. 带填充以保持分辨率的卷积层；
    2. 非线性激活函数，如ReLU；
    3. 汇聚层，如最大汇聚层
- 而一个VGG块与之类似，由一系列卷积层组成，后面再加上用于空间下采样的最大汇聚层
  -
  在最初的VGG论文中([Simonyan and Zisserman, 2014](https://zh-v2.d2l.ai/chapter_references/zreferences.html#id153 "Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556."))
  ，作者使用了带有 3×3 卷积核、填充为1（保持高度和宽度）的卷积层，和带有2×2汇聚窗口、步幅为2（每个块后的分辨率减半）的最大汇聚层
- 使用 VGG 块进行分装![[00 Attachments/Pasted image 20240607013413.png|400]]
    - 发现同样计算量开销的情况下 使用 3×3 卷积核（深度更深）会比 5×5（更浅）要来的好

### VGG 架构

- 使用 n 个 VGG 块替换![[00 Attachments/Pasted image 20240607015226.png|400]]

### 总结

- ![[00 Attachments/Pasted image 20240607015515.png|400]]
- VGG 使用可重复使用的卷积块来构建深度卷积神经网络
    - 使用可重复的块构建深度学习网络
- 不同的卷积块个数和超参数可以得到不同复杂度的变种

### 代码

#### VGG 块

- 定义一个名为 vgg_block 的函数来实现一个 VGG 块
    - 该函数有三个参数，分别对应于卷积层的数量`num_convs`、输入通道的数量`in_channels`和输出通道的数量`out_channels`

```python
import torch
from torch import nn
from d2l import torch as d2l
import time

start = time.perf_counter()


def vgg_block(num_convs, in_channels, out_channels):  # 卷积层个数、输入通道数、输出通道数  
    layers = []
    for _ in range(num_convs):
        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))
        layers.append(nn.ReLU())
        in_channels = out_channels
    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
    return nn.Sequential(*layers)  # *layers表示把列表里面的元素按顺序作为参数输入函数 *为解包操作
```

#### VGG 网络

- 与 AlexNet、LeNet 一样，VGG 网络可以分为两部分
    - 卷积层和汇聚层
    - 全连接层
- VGG 神经网络连接[图7.2.1](https://zh-v2.d2l.ai/chapter_convolutional-modern/vgg.html#fig-vgg)的几个 VGG 块（在
  `vgg_block`函数中定义）
    - 其中有超参数变量`conv_arch`。该变量指定了每个VGG块里卷积层个数和输出通道数
    - 全连接模块则与 AlexNet 中的相同
- 原始 VGG 网络有 5 个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层
    - 第一个模块有 64 个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到 512
- 由于该网络使用 8 个卷积层和 3 个全连接层，因此它通常被称为 VGG-11

```python
conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))  # 第一个参数为有几层卷积，第二个参数为输出通道数


def vgg(conv_arch):
    conv_blks = []
    in_channels = 1
    # 卷积层部分
    for (num_convs, out_channels) in conv_arch:
        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))
        in_channels = out_channels

    return nn.Sequential(
        *conv_blks, nn.Flatten(),
        # 全连接层部分
        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 10))


net = vgg(conv_arch)
```

- 构建一个高度和宽度为224的单通道数据样本，以观察每个层输出的形状

```python
# 观察每个层输出的形状  
X = torch.randn(size=(1, 1, 224, 224))
for blk in net:
    X = blk(X)
    print(blk.__class__.__name__, 'output shape:\t', X.shape)  # VGG使得高宽减半，通道数加倍
# Sequential output shape:   torch.Size([1, 64, 112, 112])  
# Sequential output shape:   torch.Size([1, 128, 56, 56])  
# Sequential output shape:   torch.Size([1, 256, 28, 28])  
# Sequential output shape:   torch.Size([1, 512, 14, 14])  
# Sequential output shape:   torch.Size([1, 512, 7, 7])  
# Flatten output shape:  torch.Size([1, 25088])  
# Linear output shape:   torch.Size([1, 4096])  
# ReLU output shape:     torch.Size([1, 4096])  
# Dropout output shape:  torch.Size([1, 4096])  
# Linear output shape:   torch.Size([1, 4096])  
# ReLU output shape:     torch.Size([1, 4096])  
# Dropout output shape:  torch.Size([1, 4096])  
# Linear output shape:   torch.Size([1, 10])
```

- 正如从代码中所看到的，我们在每个块的高度和宽度减半，最终高度和宽度都为7。最后再展平表示，送入全连接层处理

#### 训练模型

由于 VGG-11 比 AlexNet 计算量更大，因此我们构建了一个通道数较少的网络，足够用于训练 Fashion-MNIST 数据集

```python
ratio = 4
small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]  # 所有输出通道除以4  
net = vgg(small_conv_arch)
```

-

除了使用略高的学习率外（？），模型训练过程与[7.1节](https://zh-v2.d2l.ai/chapter_convolutional-modern/alexnet.html#sec-alexnet)
中的AlexNet类似

```python
lr, num_epochs, batch_size = 0.05, 10, 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
# loss 0.169, train acc 0.938, test acc 0.918  
# 474.7 examples/sec on cuda:0
# 耗时：1611.8172456秒
```

- ![[00 Attachments/Figure_10.png|400]]

## 网络中的网络（NiN）

- LeNet、AlexNet 和 VGG 都有一个共同的设计模式：
    - 通过一系列的卷积层与汇聚层来提取空间结构特征
    - 然后通过全连接层对特征的表征进行处理
- AlexNet 和 VGG 对 LeNet 的改进主要在于如何扩大和加深这两个模块
- 网络中的网络（NiN）提供了一个非常简单的解决方案：
    - 在每个像素的通道上分别使用多层感知机
- ![[00 Attachments/Pasted image 20240607080401.png]]
- ![[00 Attachments/Pasted image 20240611152355.png|400]]
    - NiN 块以一个普通卷积层开始，后面是两个 1×1 的卷积层 - 这两个 1×1 卷积层充当带有 ReLU 激活函数的逐像素全连接层 -
      第一层的卷积窗口形状通常由用户设置。 随后的卷积窗口形状固定为1×1
- 全连接层参数过多，很容易过拟合（占用内存过多，计算量太大）![[00 Attachments/Pasted image 20240607075629.png|400]]
- 所以 NiN 就完全不要全连接层
    - 全连接层不好，用卷积层替代

### NiN 块

- 卷积层的输入和输出由四维张量组成，张量的每个轴分别对应样本、通道、高度和宽度
- 全连接层的输入和输出通常是分别对应于样本和特征的二维张量
- NiN的想法是在每个像素位置（针对每个高度和宽度）应用一个全连接层
  -
  如果我们将权重连接到每个空间位置，我们可以将其视为1×1卷积层（如[6.4节](https://zh-v2.d2l.ai/chapter_convolutional-neural-networks/channels.html#sec-channels)
  中所述），或作为在每个像素位置上独立作用的全连接层
    - 另一个角度看，即将空间维度中的每个像素视为单个样本，将通道维度视为不同特征（feature）
- $1*1$ 的卷积层可以等价为一个全连接层![[00 Attachments/Pasted image 20240607081738.png|400]]

### NiN 架构

- NiN 使用窗口形状为 11×11、5×5 和 3×3 的卷积层，输出通道数量与 AlexNet 中的相同
    - 每个 NiN 块后有一个最大汇聚层，汇聚窗口形状为 3×3，步幅为 2
- 不再使用全连接层![[00 Attachments/Pasted image 20240607081803.png|400]]
    - 最后应该是 1000 个通道， 每个通道一张图。 对每张图求平均， 就是 1000 个数。代表 1000 个类别的评分
- ![[00 Attachments/Pasted image 20240607081815.png|400]]
- 全局平均池化层![[00 Attachments/Pasted image 20240607083013.png|400]]
    - 在全局平均池化层（GAP）被提出之前，常用的方式是将feature map 直接拉平成一维向量，但是GAP不同，是将每个通道的二维图像做平均，最后也就是每个通道对应一个均值
    - 假设卷积层的最后输出是h × w × d 的三维特征图，具体大小为6 × 6 × 3，经过GAP转换后，变成了大小为 1 × 1 × 3 的输出值，也就是每一层
      h × w 会被平均化成一个值，如下图所示。
    - GPA优势：
        1. 抑制过拟合。直接拉平做全连接层的方式依然保留了大量的空间信息，假设feature map是32个通道的10 *
           10图像，那么拉平就得到了32 * 10 * 10的向量，如果是最后一层是对应两类标签，那么这一层就需要3200 *
           2的权重矩阵，而GAP不同，将空间上的信息直接用均值代替，32个通道GAP之后得到的向量都是32的向量，那么最后一层只需要32 *
           2的权重矩阵。相比之下GAP网络参数会更少，而全连接更容易在大量保留下来的空间信息上面过拟合。
        2. 输入尺寸更加灵活。在第1点的举例里面可以看到feature map经过GAP后的神经网络参数不再与输入图像尺寸的大小有关，也就是输入图像的长宽可以不固定

### 总结

- ![[00 Attachments/Pasted image 20240607082952.png|400]]
    - 对每个像素通道做全连接层
    - 非线性性是由于激活函数 ReLu

### 代码实现

#### NiN 块

```python
import torch
from torch import nn
from d2l import torch as d2l


def nin_block(in_channels, out_channels, kernel_size, strides, padding):
    return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(),
                         nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),
                         nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())
```

#### NiN 模型

```python
net = nn.Sequential(
    nin_block(1, 96, kernel_size=11, strides=4, padding=0),
    nn.MaxPool2d(3, stride=2),
    nin_block(96, 256, kernel_size=5, strides=1, padding=2),
    nn.MaxPool2d(3, stride=2),
    nin_block(256, 384, kernel_size=3, strides=1, padding=1),
    nn.MaxPool2d(3, stride=2),
    nn.Dropout(0.5),
    # 标签类别数是10  
    nin_block(384, 10, kernel_size=3, strides=1, padding=1),
    nn.AdaptiveAvgPool2d((1, 1)),
    # 将四维的输出转成二维的输出，其形状为(批量大小,10)  
    nn.Flatten())
```

- 创建一个数据样本来查看每个块的输出形状

```python
X = torch.rand(size=(1, 1, 224, 224))  # 批量大小、通道数、高、宽  
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__, 'output shape:\t', X.shape)
# Sequential output shape:   torch.Size([1, 96, 54, 54])  
# MaxPool2d output shape:    torch.Size([1, 96, 26, 26])  
# Sequential output shape:   torch.Size([1, 256, 26, 26])  
# MaxPool2d output shape:    torch.Size([1, 256, 12, 12])  
# Sequential output shape:   torch.Size([1, 384, 12, 12])  
# MaxPool2d output shape:    torch.Size([1, 384, 5, 5])  
# Dropout output shape:  torch.Size([1, 384, 5, 5])  
# Sequential output shape:   torch.Size([1, 10, 5, 5])  
# AdaptiveAvgPool2d output shape:    torch.Size([1, 10, 1, 1])  
# Flatten output shape:  torch.Size([1, 10])
```

#### 训练模型

- 使用Fashion-MNIST来训练模型

```python
lr, num_epochs, batch_size = 0.1, 10, 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
# loss 0.384, train acc 0.856, test acc 0.867  
# 604.9 examples/sec on cuda:0  
# 耗时：1322.6117989秒
```

- ![[00 Attachments/Figure_12.png|400]]

## 含并行连结的网络（GoogLeNet）

- GoogLeNet([Szegedy _et
  al._, 2015](https://zh-v2.d2l.ai/chapter_references/zreferences.html#id162 "Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., … Rabinovich, A. (2015). Going deeper with convolutions. Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1–9)."))
  吸收了 NiN 中串联网络的思想，并在此基础上做了改进
    - 这篇论文的一个重点是解决了什么样大小的卷积核最合适的问题
    - 本文的一个观点是，有时使用不同大小的卷积核组合是有利的
- 使用哪个卷积核，在哪里使用什么池化层？

### Inception块

- 在 GoogLeNet 中，基本的卷积块被称为 Inception 块（Inception block）
- 4 个路径从不同层面抽取信息，然后再输出通道维合并![[00 Attachments/Pasted image 20240611175513.png]]
    - Inception 块由四条并行路径组成
        - 前三条路径使用窗口大小为 1×1、3×3 和 5×5 的卷积层，从不同空间大小中提取信息
        - 中间的两条路径在输入上执行 1×1 卷积，以==减少通道数，从而降低模型的复杂性==
        - 第四条路径使用 3×3 最大池化层，然后使用 1×1 卷积层来改变通道数
    - 这四条路径都使用合适的填充来使==输入与输出的高和宽一致==
    - 最后将每条线路的输出在通道维度上连结，并构成 Inception 块的输出
- 在 Inception 块中，通常调整的超参数是每层输出通道数
- ![[00 Attachments/Pasted image 20240611180532.png|400]]
    - 白色的卷积用来改变通道数，蓝色的卷积用来抽取信息
    - 最左边一条1X1卷积是用来抽取通道信息，其他的3X3卷积用来抽取空间信息
    - 一同输出了 $64 + 128 + 32 + 32 = 256$ 个通道
- 参数个数与计算量![[00 Attachments/Pasted image 20240611180939.png|400]]
    - 输出相同的通道数，5X5比3X3的卷积层参数个数多，3X3比1X1卷积层的参数个数多
    - Inception块使用了大量1X1卷积层，使得参数相对单3X3、5X5卷积层更少
- 那么为什么 GoogLeNet 这个网络如此有效呢？
    - 首先我们考虑一下滤波器（filter）的组合，它们可以用各种滤波器尺寸探索图像，这意味着不同大小的滤波器可以有效地识别不同范围的图像细节
    - 同时，我们可以为不同的滤波器分配不同数量的参数

### GoogLeNet

- GoogLeNet 一共使用 9 个 Inception
  块和全局平均汇聚层的堆叠来生成其估计值![[00 Attachments/Pasted image 20240613150741.png|400]]
    - 高宽减半叫一个 stage

### 代码实现

#### Inception 块

```python
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l


class Inception(nn.Module):
    # c1--c4是每条路径的输出通道数  
    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):
        super(Inception, self).__init__(**kwargs)
        # 线路1，单1x1卷积层  
        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)
        # 线路2，1x1卷积层后接3x3卷积层  
        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)
        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)
        # 线路3，1x1卷积层后接5x5卷积层  
        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)
        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)
        # 线路4，3x3最大汇聚层后接1x1卷积层  
        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)

    def forward(self, x):
        p1 = F.relu(self.p1_1(x))  # relu激活函数  
        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))
        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))
        p4 = F.relu(self.p4_2(self.p4_1(x)))
        # 在通道维度上连结输出  
        return torch.cat((p1, p2, p3, p4), dim=1)  # cat函数用于在通道维度上连结输出
```

#### 各个模块

- 第一、二个模块![[00 Attachments/Pasted image 20240613151000.png|400]]
- 第一个模块使用 64 个通道、7 × 7 卷积层

```python
b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3), nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
```

- 第二个模块使用两个卷积层
    - 第一个卷积层是 64 个通道、1 × 1 卷积层
    - 第二个卷积层使用将通道数量增加三倍 3 × 3 卷积层

```python
b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1), nn.ReLU(),
                   nn.Conv2d(64, 192, kernel_size=3, padding=1), nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
```

- 第三个模块![[00 Attachments/Pasted image 20240613155237.png|400]]
- 串联两个完整的 Inception 块
    - 第一个 Inception 块的输出通道数为 64+128+32+32=256，四个路径之间的输出通道数量比为 64:128:32:32=2:4:1:1
        - 第二个和第三个路径首先将输入通道的数量分别减少到 96/192=1/2和 16/192=1/12，然后连接第二个卷积层
    - 第二个 Inception 块的输出通道数增加到 128+192+96+64=480，四个路径之间的输出通道数量比为 128:192:96:64=4:6:3:2
        - 第二条和第三条路径首先将输入通道的数量分别减少到 128/256=1/2 和 32/256=1/8

```python
b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),
                   Inception(256, 128, (128, 192), (32, 96), 64),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
```

- 第四、五个模块![[00 Attachments/Pasted image 20240613155249.png|400]]
- 第四模块串联了 5 个 Inception 块，其输出通道数分别是
  192+208+48+64=512、160+224+64+64=512、128+256+64+64=512、112+288+64+64=528 和 256+320+128+128=832
    - 这些路径的通道数分配和第三模块中的类似，首先是含 3×3 卷积层的第二条路径输出最多通道，其次是仅含 1×1 卷积层的第一条路径，之后是含
      5×5 卷积层的第三条路径和含 3×3 最大汇聚层的第四条路径。
    - 其中第二、第三条路径都会先按比例减小通道数。 这些比例在各个 Inception 块中都略有不同

```python
b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),
                   Inception(512, 160, (112, 224), (24, 64), 64),
                   Inception(512, 128, (128, 256), (24, 64), 64),
                   Inception(512, 112, (144, 288), (32, 64), 64),
                   Inception(528, 256, (160, 320), (32, 128), 128),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
```

- 第五模块包含输出通道数为 256+320+128+128=832 和 384+384+128+128=1024 的两个 Inception 块
    - 其中每条路径通道数的分配思路和第三、第四模块中的一致，==只是在具体数值上有所不同==
    - 需要注意的是，第五模块的后面紧跟输出层，该模块同 NiN 一样使用全局平均汇聚层，将每个通道的高和宽变成1。
      最后我们将输出变成二维数组，再接上一个输出个数为标签类别数的全连接层

```python
b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),
                   Inception(832, 384, (192, 384), (48, 128), 128),
                   nn.AdaptiveAvgPool2d((1, 1)),
                   nn.Flatten())

net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))
```

- AdaptiveAvgPool2d()
    - 在实际的项目当中，我们往往预先只知道的是输入数据和输出数据的大小，而不知道核与步长的大小。
    - 我们可以手动计算核的大小和步长的值。而自适应（Adaptive）能让我们从这样的计算当中解脱出来，==只要我们给定输入数据和输出数据的大小，自适应算法能够自动帮助我们计算核的大小和每次移动的步长==
    - 相当于我们对核说，我已经给你输入和输出的数据了，你自己适应去吧。你要长多大，你每次要走多远，都由你自己决定，总之最后你的输出符合我的要求就行了。
    - 比如我们给定输入数据的尺寸是9， 输出数据的尺寸是3，那么自适应算法就能自动帮我们计算出，核的大小是3，每次移动的步长也是3，然后依据这些数据，帮我们创建好池化层。
    - GoogLeNet 模型的计算复杂，而且不如VGG那样便于修改通道数
- 为了使 Fashion-MNIST 上的训练短小精悍，我们将输入的高和宽从 224 降到 96，这简化了计算

```python
X = torch.rand(size=(1, 1, 96, 96))
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__, 'output shape:\t', X.shape)
# Sequential output shape:   torch.Size([1, 64, 24, 24])  
# Sequential output shape:   torch.Size([1, 192, 12, 12])  
# Sequential output shape:   torch.Size([1, 480, 6, 6])  
# Sequential output shape:   torch.Size([1, 832, 3, 3])  
# Sequential output shape:   torch.Size([1, 1024])  
# Linear output shape:   torch.Size([1, 10])
```

#### 训练模型

- 使用 Fashion-MNIST 数据集来训练我们的模型。在训练之前，我们将图片转换为 96×96 分辨率

```python
lr, num_epochs, batch_size = 0.1, 10, 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
# loss 0.256, train acc 0.902, test acc 0.869  
# 830.3 examples/sec on cuda:0  
# 耗时: 874.2482681 秒
```

- ![[00 Attachments/Figure_13.png|400]]

### Inception 后续变种

- ![[00 Attachments/Pasted image 20240613161312.png|400]]
- ![[00 Attachments/Pasted image 20240613161319.png|400]]
- ![[00 Attachments/Pasted image 20240613161333.png|400]]

### 总结

- ![[00 Attachments/Pasted image 20240613161346.png|400]]

## 批量归一化（batch normalization）

### 深层网络的挑战

1. 数据预处理的方式通常会对最终结果产生巨大影响
    - 使用真实数据时，我们的第一步是标准化输入特征，使其平均值为0，方差为1。 直观地说，这种标准化可以很好地与我们的优化器配合使用，因为它可以将参数的量级进行统一
2. 对于典型的多层感知机或卷积神经网络
    - 当我们训练时，中间层中的变量（例如，多层感知机中的仿射变换输出）可能具有更广的变化范围：
        - ==不论是沿着从输入到输出的层，跨同一层中的单元，或是随着时间的推移，模型参数的随着训练更新变幻莫测==
        - 批量归一化的发明者非正式地假设：
            - ==这些变量分布中的这种偏移可能会阻碍网络的收敛==（变得不稳定）
            - 直观地说，我们可能会猜想，如果一个层的可变值是另一层的100倍，这可能需要对学习率进行补偿调整
3. 更深层的网络很复杂，容易过拟合。 这意味着正则化变得更加重要

- ![[00 Attachments/Pasted image 20240613165046.png|400]]
    - 损失函数越到后面会越小（梯度消失），会导致底层参数更新幅度较小，导致更新变慢
    - 上层梯度较大，参数可能很快就训练完成，下层梯度较小，参数学习较慢，而下层的参数又影响上层的参数（使上层重新拟合底部的变换），导致==收敛变慢==

### 批量归一化

- 加速收敛
- 批量归一化应用于单个可选层（也可以应用到所有层），其原理如下
    - 在每次训练迭代中，首先归一化化输入，即通过减去其均值并除以其标准差，其中两者均基于当前小批量处理
    - 接下来，我们应用比例系数和比例偏移。 正是由于这个基于批量统计的标准化，才有了批量规范化的名称
- 有点像独立同分布的中心极限定理
    - 假设$\{X_n\}$是独立同分布的随机变量序列，如果$EX_i=\mu,DX_i=\sigma^2$存在
    - $\sum_{i=1}^nX_i \sim N(n\mu,n\sigma^2)$
    - 然后将其转化为标准正态分布
- 中心极限定理的条件：满足大量样本（$x_i$）
- 两个学习参数：伽马，贝塔![[00 Attachments/Pasted image 20240613175556.png|400]]
    - 拉伸参数（scale）𝛾 和偏移参数（shift）𝛽，它们的形状与 𝑥 相同
- 可能是通过加入噪音来控制模型的复杂度![[00 Attachments/Pasted image 20240613181423.png|400]]
    - 这个小批量数据实随机的，算出来的统计量也可以说是随机的。
    - 因为每个 batch 的均值和方差都不太一样。
    - 因为每次取得 batch 中的数据都是不同的，所以在batch中计算的均值和方差也是不同的，所以引入了随机性。

### 批量归一化层

- ![[00 Attachments/Pasted image 20240613180638.png|400]]
    - 在每个批量里，1个像素是1个样本。与像素（样本）对应的通道维，就是特征维（全连接的特征为 x 的每一列）
    - 所以==不是对单个通道的特征图做均值方差，而是对单个像素的不同通道做均值方差==
    - 输入 9 个像素(3x3), 输出 3 通道，以通道作为列分量，每个像素都对应 3 列(输出通道=3)，可以列出表格，按列求均值和方差
    - 其实和全连接层一样的。即像素为样本，通道为特征
- 批量规范化层在”训练模式“（通过小批量统计数据规范化）和“预测模式”（通过数据集统计规范化）中的功能不同
    - 在训练过程中，我们无法得知使用整个数据集来估计平均值和方差，所以只能根据每个小批次的平均值和方差不断训练模型
    - 而在预测模式下，可以根据整个数据集精确计算批量规范化所需的平均值和方差

### 总结

- 当每一个层的均值和方差都固定后，学习率太大的话，靠近 loss 上面的梯度太大，就梯度爆炸了，学习率太小的话，靠近数据的梯度太小了，就算不动（梯度消失）
- 将每一层的输入放在一个差不多的分布里，就可以用一个比较大的精度了，就可以加速收敛速度
- 归一化不会影响数据分布，它一点都不会影响精度，变好变坏都不会
- ![[00 Attachments/Pasted image 20240613182630.png|400]]
    - 加速收敛：学习率可以调得更大

### 代码实现

#### 从零开始

- 批量归一化函数

```python
import torch
from torch import nn
from d2l import torch as d2l
import time


def batch_norm(X, gamma, beta, moving_mean, moving_var, eps,
               momentum):  # X为输入，gamma、beta为学的参数。moving_mean、moving_var为全局的均值、方差。eps为避免除0的参数。momentum为更新moving_mean、moving_var的  
    # 通过is_grad_enabled来判断当前模式是训练模式还是预测模式  
    if not torch.is_grad_enabled():
        # 'is_grad_enabled' 来判断当前模式是训练模式还是预测模式。就是在做推理的时候，推理不需要反向传播，所以不需要计算梯度  
        X_hat = (X - moving_mean) / torch.sqrt(
            moving_var + eps)  # 做推理时，可能只有一个图片进来，没有一个批量进来，因此这里用的全局的均值、方差。在预测中，一般用整个预测数据集的均值和方差。加eps为了避免方差为0，除以0了  
    else:
        assert len(X.shape) in (2, 4)  # 批量数+通道数+图片高+图片宽=4  
        if len(X.shape) == 2:  # 2 表示有两个维度，批量大小和特征  
            # 使用全连接层的情况，计算特征维上的均值和方差  
            mean = X.mean(dim=0)  # 按行求均值，即对每个特征维求一个均值  
            var = ((X - mean) ** 2).mean(dim=0)
        else:  # == 4 表示有四个维度，批量数、通道数、图片高、图片宽  
            # 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差
            # 这里我们需要保持X的形状以便后面可以做广播运算  
            mean = X.mean(dim=(0, 2, 3), keepdim=True)  # 沿通道维度求均值  
            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)
            # 训练模式下，用当前的均值和方差做标准化  
        X_hat = (X - mean) / torch.sqrt(var + eps)
        # 更新移动平均的均值和方差  
        moving_mean = momentum * moving_mean + (
                1.0 - momentum) * mean  # 累加，将计算的均值累积到全局的均值上，更新moving_mean momentum 一般为0.9，即前一轮的均值和当前的均值做加权平均。  
        moving_var = momentum * moving_var + (1.0 - momentum) * var  # 当前全局的方差与当前算的方差做加权平均，最后会无限逼近真实的方差。仅训练时更新，推理时不更新  
    Y = gamma * X_hat + beta  # Y 为归一化后的输出  
    return Y, moving_mean.data, moving_var.data
```

- 批量归一化层

```python
class BatchNorm(nn.Module):
    # num_features：完全连接层的输出数量或卷积层的输出通道数。  
    # num_dims：2表示完全连接层，4表示卷积层  
    def __init__(self, num_features, num_dims):
        super().__init__()
        if num_dims == 2:  # 全连接层的情况  
            shape = (1, num_features)
        else:  # 卷积层的情况  
            shape = (1, num_features, 1, 1)
            # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0  
        self.gamma = nn.Parameter(torch.ones(shape))
        self.beta = nn.Parameter(torch.zeros(shape))
        # 非模型参数的变量初始化为0和1  
        # 伽马、贝塔需要在反向传播时更新，所以放在nn.Parameter里面，moving_mean、moving_var不需要迭代，所以不放在里面  
        self.moving_mean = torch.zeros(shape)
        self.moving_var = torch.ones(shape)

    def forward(self, X):
        # 如果X不在内存上，将moving_mean和moving_var  
        # 复制到X所在显存上  
        if self.moving_mean.device != X.device:
            self.moving_mean = self.moving_mean.to(X.device)
            self.moving_var = self.moving_var.to(X.device)
            # 保存更新过的moving_mean和moving_var  
        Y, self.moving_mean, self.moving_var = batch_norm(
            X, self.gamma, self.beta, self.moving_mean,
            self.moving_var, eps=1e-5, momentum=0.9)
        return Y
```

- 在 LeNet 网络中使用批量归一化层

```python
net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5), BatchNorm(6, num_dims=4), nn.Sigmoid(),  ## BatchNorm 的特征维度为 6 即为通道  
    nn.AvgPool2d(kernel_size=2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), BatchNorm(16, num_dims=4), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),
    nn.Linear(16 * 4 * 4, 120), BatchNorm(120, num_dims=2), nn.Sigmoid(),
    nn.Linear(120, 84), BatchNorm(84, num_dims=2), nn.Sigmoid(),
    nn.Linear(84, 10))
```

- 训练

```python
lr, num_epochs, batch_size = 1.0, 10, 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
print(net[1].gamma.reshape((-1,)), net[1].beta.reshape((-1,)))
# loss 0.266, train acc 0.901, test acc 0.853  
# 25011.8 examples/sec on cuda:0  
# tensor([2.8180, 2.9079, 1.5509, 2.0058, 4.7415, 3.1875], device='cuda:0',  
#        grad_fn=<ViewBackward0>)  
# tensor([-3.1075,  2.9179, -1.1533,  1.9685, -1.7691,  1.3454], device='cuda:0',  
#        grad_fn=<ViewBackward0>)  
# Time taken: 86.5487827 seconds
```

- ![[00 Attachments/Figure_14.png|400]]
- 与 6.5 LeNet 相比，训练得更快了，但是精度没有变

#### 简洁实现

```python
net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),
    nn.Linear(256, 120), nn.BatchNorm1d(120), nn.Sigmoid(),
    nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(),
    nn.Linear(84, 10))

d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
# loss 0.265, train acc 0.902, test acc 0.863  
# 27979.6 examples/sec on cuda:0  
# Time taken: 85.2087728 seconds
```

- ![[00 Attachments/Pasted image 20240613194045.png|400]]

## 残差网络（ResNet）

- 随着我们设计越来越深的网络，深刻理解“新添加的层如何提升神经网络的性能”变得至关重要
- 更重要的是设计网络的能力，在这种网络中，添加层会使网络更具表现力， 为了取得质的突破，我们需要一些数学基础知识

- ResNet 是一种深度卷积神经网络架构，旨在解决随着网络层数增加而导致的梯度消失和性能下降问题。它通过引入残差学习（residual
  learning）机制，使得网络能够学习到输入与输出之间的残差，而不是直接学习输入和输出之间的映射。ResNet 通过使用快捷连接（skip
  connections）将输入直接传递到后面的层，从而促进了信息的流动，使得更深的网络在训练时能够表现得更好。ResNet
  在多个计算机视觉任务中取得了显著的成功，并成为深度学习领域的重要基准模型

### 嵌套函数类

- 怎样得到更近似真正 $𝑓^∗$ 的函数呢？![[00 Attachments/Pasted image 20240613223159.png|400]]
    - 对于非嵌套函数（non-nested function）类，较复杂的函数类并不总是向“真”函数𝑓∗靠拢（复杂度由𝐹1向𝐹6递增）
        - 在图的左边，虽然 $𝐹_3$ 比 $𝐹_1$ 更接近 $𝑓^∗$，但 $𝐹_6$ 却离的更远了
    - 对于非嵌套函数类，较复杂（由较大区域表示）的函数类不能保证更接近“真”函数（$𝑓^∗$）。这种现象在嵌套函数类中不会发生
- 因此，只有当较复杂的函数类包含较小的函数类时，我们才能确保提高它们的性能
- 对于深度神经网络，如果我们能将新添加的层训练成恒等映射（identity function）$𝑓(𝑥)=𝑥$，新模型和原模型将同样有效
    - 同时，由于新模型可能得出更优的解来拟合训练数据集，因此添加层似乎更容易降低训练误差

### 残差块

- 残差网络的核心思想是：==每个附加层都应该更容易地包含原始函数作为其元素之一==
- ![[00 Attachments/Pasted image 20240613224441.png|400]]
    - ResNet 沿用了 VGG 完整的 3×3 卷积层设计
        - 残差块里首先有 2 个有相同输出通道数的 3×3 卷积层。每个卷积层后接一个批量规范化层和ReLU激活函数
        - 然后通过跨层数据通路，跳过这 2 个卷积运算，将输入直接加在最后的 ReLU 激活函数前
        - 这样的设计==要求 2 个卷积层的输出与输入形状一样，从而使它们可以相加==
            - 如果想改变通道数，就需要引入一个额外的 1×1 卷积层来将输入变换成需要的形状后再做相加运算
    - 这样直接加==保证了最优解“至少不会变差”==
        - 假设没有学到任何东西，则 $g(x)$ 为0，那么输出依然为 x（在原来的基础上）
    - 这个 $x$ 实际上是 $f_0(x)$，就是上幅图小的部分，$f(x)$ 是 $f_1(x)$，新函数包含原函数
    - 那么这个就可以视作在原来的函数基础上加上复杂度（泰勒展开到 2 次，展开到 5 次，5 次在 2 次的基础上更相似于被泰勒展开的函数）
- 如果通道改变的话，可以使 x 通过一个 1×1 的卷积层（方便于 g(x)
  相加）![[00 Attachments/Pasted image 20240613225150.png|400]]
- 残差块可以加在任何地方（排列组合）![[00 Attachments/Pasted image 20240613225442.png|400]]
- 两种残差块（包含 1×1 卷积或不包含）![[00 Attachments/Pasted image 20240613225954.png|400]]

### ResNet 架构

- ![[00 Attachments/Pasted image 20240613230912.png|400]]
    - ResNet 的前两层跟之前介绍的 GoogLeNet 中的一样
        - 在输出通道数为 64、步幅为 2 的 7×7 卷积层后，接步幅为 2 的 3×3 的最大汇聚层
        - 不同之处在于 ResNet 每个卷积层后增加了批量归一化层
    - GoogLeNet 在后面接了 4 个由 Inception 块组成的模块。ResNet则使用4个由残差块组成的模块，每个模块使用若干个同样输出通道数的残差块
        - 第一个模块的通道数同输入通道数一致
            - 由于之前已经使用了步幅为 2 的最大汇聚层，所以无须减小高和宽
        - 之后的每个模块在第一个残差块里将上一个模块的通道数翻倍，并将高和宽减半
    - 每个模块有 4 个卷积层（不包括恒等映射的1×1卷积层，即两个残差块）
        - 加上第一个 7×7 卷积层和最后一个全连接层，共有18层。因此，这种模型通常被称为ResNet-18。
        - 通过配置不同的通道数和模块里的残差块数可以得到不同的 ResNet 模型，例如更深的含 152 层的 ResNet-152。
        - ==虽然 ResNet 的主体架构跟 GoogLeNet 类似，但 ResNet 架构更简单，修改也更方便==。这些因素都导致了 ResNet 迅速被广泛使用

### 总结

- ==resnet 是保留了原先模型的基础上继续扩大（学习），不至于会学偏==
- ![[00 Attachments/Pasted image 20240613232539.png|400]]
- 训练深层神经网络时由于计算梯度时的链式法则中的乘法导致容易在靠近输入的层出现梯度消失（如果在浅层已经拟合的较好时，变化率就会很小）的问题，resnet
  通过使用加法规避了这个问题（做了个加法），因此可以训练非常深的神经网络

### 代码实现

#### 残差块

```python
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l


class Residual(nn.Module):
    def __init__(self, input_channels, num_channels, use_1x1conv=False, strides=1):  # num_channels为输出channel数  
        super().__init__()
        self.conv1 = nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1,
                               stride=strides)
        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)
        if use_1x1conv:
            self.conv3 = nn.Conv2d(input_channels, num_channels, kernel_size=1, stride=strides)
        else:
            self.conv3 = None
        self.bn1 = nn.BatchNorm2d(num_channels)
        self.bn2 = nn.BatchNorm2d(num_channels)
        self.relu = nn.ReLU(inplace=True)  # inplace原地操作，不创建新变量，对原变量操作，节约内存  

    def forward(self, X):
        Y = F.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))
        if self.conv3:
            X = self.conv3(X)
        Y += X
        return F.relu(Y)
```

- 查看输入输出的形状

```python
blk = Residual(3, 3)  # 输入三通道，输出三通道  
X = torch.rand(4, 3, 6, 6)
Y = blk(X)  # stride用的默认的1，所以宽高没有变化。如果strides用2，则宽高减半  
print(Y.shape)
# torch.Size([4, 3, 6, 6])
```

- 增加输出通道数的同时，减半输出的高和宽

```python
print(blk(X).shape)
# torch.Size([4, 6, 3, 3])
```

#### ResNet 模型

- ResNet 的第一个 stage

```python
b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
                   nn.BatchNorm2d(64), nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
```

- 其余 stage 为残差块组成的模块（大 block）
    - 对第一个模块进行了特殊处理

```python
def resnet_block(input_channels, num_channels, num_residuals, first_block=False):  # num_residuals为每个block的残差层数  
    blk = []
    for i in range(num_residuals):
        # 如果是第一个 stage,则第一个残差块输出通道，形状不变；否则第一个残差块输出通道数加倍，形状减半  
        if i == 0 and not first_block:
            blk.append(Residual(input_channels, num_channels, use_1x1conv=True, strides=2))
        else:
            blk.append(Residual(num_channels, num_channels))
    return blk


# 在ResNet加入所有残差块，这里每个模块使用2个残差块
b2 = nn.Sequential(*resnet_block(64, 64, 2,
                                 first_block=True))  # 因为b1做了两次宽高减半，nn.Conv2d、nn.MaxPool2d，所以b2中的首次就不减半了      b3 = nn.Sequential(*resnet_block(64, 128, 2))  # b3、b4、b5的首次卷积层都减半  
b4 = nn.Sequential(*resnet_block(128, 256, 2))
b5 = nn.Sequential(*resnet_block(256, 512, 2))

net = nn.Sequential(b1, b2, b3, b4, b5, nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(), nn.Linear(512, 10))
```

- ResNet 中不同模块的输入形状是如何变化

```python
X = torch.rand(size=(1, 1, 224, 224))
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__, 'output shape:\t', X.shape)  # 通道数翻倍、模型减半  
# Sequential output shape:   torch.Size([1, 64, 56, 56])  
# Sequential output shape:   torch.Size([1, 64, 56, 56])  
# Sequential output shape:   torch.Size([1, 128, 28, 28])  
# Sequential output shape:   torch.Size([1, 256, 14, 14])  
# Sequential output shape:   torch.Size([1, 512, 7, 7])  
# AdaptiveAvgPool2d output shape:    torch.Size([1, 512, 1, 1])  
# Flatten output shape:  torch.Size([1, 512])  
# Linear output shape:   torch.Size([1, 10])
```

#### 训练模型

```python
lr, num_epochs, batch_size = 0.05, 10, 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
# loss 0.016, train acc 0.996, test acc 0.915  
# 1051.2 examples/sec on cuda:0  
# 耗时: 11.964245716666666分钟
```

- ![[00 Attachments/Figure_15.png|400]]
