```toc
```

# 3.1、线性神经网络

## 3.1.1 线性回归

- 回归（regression）是能为一个或多个自变量与因变量之间关系建模的一类方法
- 当我们想预测一个数值时，就会涉及到回归问题。但不是所有的预测都是回归问题

### 3.1.1.1 简化模型

- 举例![[00 Attachments/Pasted image 20240510151211.png|500]]
- 线性回归模型![[00 Attachments/Pasted image 20240510151446.png|500]]

### 3.1.1.2 神经网络

- 线性模型可视作单层神经网络![[00 Attachments/Pasted image 20240510151706.png|500]]
    - 输入的维度为 d，输出的维度为 1，每一个箭头代表权重
    - 带权重的层只有一层，所以是单层神经网络。（输出层不算，因为不带权重）
- 对于线性回归，每个输入都与每个输出（在本例中只有一个输出）相连， 我们将这种变换（上图中的输出层） 称为==全连接层==（fully-connected
  layer）或称为_稠密层_（dense layer）
- ![[00 Attachments/Pasted image 20240510152256.png|500]]
    - 随着不断发展，神经网络已经超出了神经科学的范畴

### 3.1.1.3 求最优解

- ![[00 Attachments/Pasted image 20240510154956.png|500]]
    - 损失函数
        - 考虑如何用模型拟合（fit）数据之前，需要确定一个拟合程度的度量
        - ==损失函数==（loss function）能够量化目标的实际值与预测值之间的差距
        - 平方误差函数
            - $$l^{(i)}(\mathbf{w}, b) = \frac{1}{2} \left(\hat{y}^{(i)} - y^{(i)}\right)^2$$
            - 二分之一是为了求导后消去系数
            - 举例![[00 Attachments/Pasted image 20240510153706.png|300]]
                - 由于平方误差函数中的二次方项， 估计值 $\hat 𝑦^{(𝑖)}$ 和观测值 $𝑦^{(𝑖)}$
                  之间较大的差异将导致更大的损失$$L(\mathbf{w}, b) =\frac{1}{n}\sum_{i=1}^n l^{(i)}(\mathbf{w}, b) =\frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right)^2$$
                - 训练模型时，希望找到一组参数 $(𝑤^∗,𝑏^∗)$，
                  这组参数能最小化在所有训练样本上的总损失（最优解）$$\mathbf{w}^*, b^* = \operatorname*{argmin}_{\mathbf{w}, b}\ L(\mathbf{w}, b)$$
- ![[00 Attachments/Pasted image 20240510154852.png|500]]
    - X 为输入，y 为实际数据。（一一对应）
- 求最优解![[00 Attachments/Pasted image 20240510155800.png|500]]
    - 除 n 是为了归一化
- 解析解![[00 Attachments/Pasted image 20240510160332.png|500]]
    - ![[00 Attachments/a83f4c3e256df61aaa0debe916393c6.jpg|200]]
    - 将偏置 𝑏 合并到参数 𝑤
      中$$\mathbf{X} = [\mathbf x_1,\mathbf x_2,...,\mathbf x_n,\mathbf 1]^T，\mathbf{w} = [w_1,w_2,...,w_n,b]^T$$
        - $$\mathbf {\hat y} = \mathbf X \mathbf w=
          \begin{bmatrix}  
          x_{00} & \cdots & x_{0m} & 1\\  
          \vdots & \ddots & \vdots & 1\\  
          x_{n0} & \cdots & x_{nm} & 1
          \end{bmatrix}
          \begin{bmatrix}  
          w_{0} \\  
          \vdots \\  
          w_{m} \\
          b
          \end{bmatrix} $$
        - 共有 n 组数据，每组数据有 m 个影响因素（输入）
    - 线性回归是一个很简单的优化问题，他的解可以用一个公式简单地表达出来

### 总结

- 线性回归是对 n 维输入的加权，外加偏差
- 使用平方损失来衡量预测值和真实值的差异
- 线性回归有解析
- 线性回归可以看做是单层神经网络

## 3.1.2 基础优化算法

### 3.1.2.1 梯度下降

- 梯度下降（gradient descent）：通过计算损失函数关于参数的梯度（导数），找到损失函数减小的方向，并沿着该方向更新参数以减小损失函数
- 举例![[00 Attachments/Pasted image 20240510201555.png|500]]
    - ==超参数==（hyperparameter）：可以调整但不在训练过程中更新的参数
    - 调参（hyperparameter tuning）是选择超参数的过程
    - 超参数通常是我们根据训练迭代结果来调整的， 而训练迭代结果是在独立的验证数据集（validation dataset）上评估得到的
    - ![[00 Attachments/Pasted image 20240510204637.png|500]]
- 学习率的选择![[00 Attachments/Pasted image 20240510205154.png|500]]
    - 不能太小，费时。且梯度计算是模型中最耗资源的部分（每次计算梯度，需要对损失函数求导，而损失函数是对所有样本的一个平均损失，这意味着求一次梯度需要将样本重新计算一遍）
    - 不能太大。超调振荡

### 3.1.2.2 小批量随机梯度下降

- ![[00 Attachments/Pasted image 20240510205521.png|500]]
    - $$\begin{split}\begin{aligned} \mathbf{w} &\leftarrow \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{\mathbf{w}} l^{(i)}(\mathbf{w}, b) = \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \mathbf{x}^{(i)} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right),\\ b &\leftarrow b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_b l^{(i)}(\mathbf{w}, b)  = b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right). \end{aligned}\end{split}$$
- 批量（batch size）：随机样本个数
- 批量的选择
    - 不能太小：每次计算量太小，不合适并行来最大利用计算资源
    - 不能太大：内存消耗增加，浪费计算。例如如果所有样本都是相同的（存在大量近似的样本）

### 3.1.2.3 总结

- 梯度下降通过不断沿着反梯度方向更新参数求解
- 小批量随机梯度下降是深度学习默认的求解算法
- 两个重要的超参数是批量大小和学习率

## 3.1.3 线性回归从零开始

- 不使用任何深度学习框架提供的计算， 从零开始实现整个方法，包括数据流水线、模型、损失函数和小批量随机梯度下降优化器

### 3.1.3.1 生成数据集

- 根据带有噪声的线性模型构造一个人造数据集。使用线性模型参数 $𝑤=[2,−3.4]⊤$、$𝑏=4.2$ 和噪声项 ϵ
  生成数据集及其标签：$$𝑦=𝑋𝑤+𝑏+𝜖$$

```python
def synthetic_data(w, b, num_examples):  # 生成数据集  
    """生成y = Xw + b + 噪声"""
    X = torch.normal(0, 1, (num_examples, len(w)))  # 随机生成 num_examples 行 len(w) 列的矩阵  
    y = torch.matmul(X, w) + b  # 计算 y = Xw + b    y += torch.normal(0, 0.01, y.shape)  # 加上噪声  
    return X, y.reshape((-1, 1))  # 返回 X 和 转置后的 y -1自动将y的形状转为(num_examples,1)  


true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 1000)  # features中的每一行都包含一个二维数据样本， labels中的每一行都包含一维标签值（一个标量）
```

- `features`中的每一行都包含一个二维数据样本，`labels`中的每一行都包含一维标签值（一个标量）

```python
print('features:', features[0], '\nlabel:', labels[0])  # 打印第一个样本的特征和标签  
# features: tensor([-1.0186, -0.1225])  
# label: tensor([2.5836])
```

- 通过生成第二个特征`features[:, 1]`和`labels`的散点图， 可以直观观察到两者之间的线性关系

```python
d2l.set_figsize()
d2l.plt.scatter(features[:, 1].detach().numpy(), labels.detach().numpy(), 1)  # 只有 detach 后才能转到 numpy 里面去
```

- `set_figsize()`：Set the figure size for matplotlib
- ![[00 Attachments/Pasted image 20240510221414.png|500]]

### 3.1.2.2 读取数据集

- `data_iter()`接收批量大小、特征矩阵和标签向量作为输入，生成大小为 batch_size 的小批量

```python
def data_iter(batch_size, features, labels):  # 生成小批量数据集  
    num_examples = len(features)
    indices = list(range(num_examples))
    random.shuffle(indices)  # 对样本索引进行随机重排序，以便以每次迭代取出不同的数据子集  
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)])  # 最后一次可能不足一个 batch_size，因此用 min 函数限制范围  
        yield features[batch_indices], labels[batch_indices]  # yield 关键字用于生成迭代器，返回一个生成器对象，可以用 next() 函数获取下一个值
```

- `yield`关键字在 Python 中用于定义生成器函数，它可以暂停函数的执行并返回一个中间值，然后在需要时从上次暂停的地方继续执行，而不会丢失任何状态信息
  ```python
  def my_generator():
      yield 1
      yield 2
      yield 3
  
  gen = my_generator()
  
  print(next(gen))  # 输出 1
  print(next(gen))  # 输出 2
  print(next(gen))  # 输出 3
  ```
- 如果`batch_indices`的值是`tensor([2, 5, 7, 9, 10])`，那么`features[batch_indices]`和`labels[batch_indices]`
  将会包含数据集中索引为2、5、7、9和10的特征和标签数据
- 利用GPU并行运算的优势，处理合理大小的“小批量”。每个样本都可以并行地进行模型计算，且每个样本损失函数的梯度也可以被并行计算。
  GPU可以在处理几百个样本时，所花费的时间不比处理一个样本时多太多
- 直观感受一下小批量运算：读取第一个小批量数据样本并打印

```python
batch_size = 10
for X, y in data_iter(batch_size, features, labels):
    """  
    运行迭代时，会连续地获得不同的小批量，直至遍历完整个数据集  
    循环一次，调用一次data_iter()  
    每次迭代返回一个小批量的特征和标签  
    再次调用时（由于yield关键字）从上次的位置继续  
    """
    print(X, '\n', y)
    break
# tensor([[-0.1774,  0.9301],  
#         [ 2.0726, -0.8996],  
#         [-0.7972, -0.3161],  
#         [ 0.0052, -1.3159],  
#         [-0.1677,  1.6213],  
#         [-0.7590,  1.0103],  
#         [-0.9327,  1.1352],  
#         [ 0.4481, -1.5346],  
#         [ 0.4171,  0.0842],  
#         [-0.5942, -1.3337]])  
#  tensor([[ 0.6886],  
#         [11.4139],  
#         [ 3.6750],  
#         [ 8.6796],  
#         [-1.6448],  
#         [-0.7698],  
#         [-1.5164],  
#         [10.3102],  
#         [ 4.7424],  
#         [ 7.5442]])
```

### 3.1.2.3 初始化模型参数

- 在开始用小批量随机梯度下降优化模型参数之前， 需要先有一些参数。 在下面的代码中，通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重，
  并将偏置初始化为0

```python
w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True)  # 随机初始化权重 requires_grad=True 表示需要对 w 进行求导  
b = torch.zeros(1, requires_grad=True)  # 偏置初始化为0
```

- 在初始化参数之后，我们的任务是更新这些参数，直到这些参数足够拟合我们的数据。 每次更新都需要计算损失函数关于模型参数的梯度。
  有了这个梯度，我们就可以向减小损失的方向更新每个参数。

### 3.1.2.4 定义模型

- 将模型的输入和参数同模型的输出关联起来$$\hat y = \mathbf{Xw} + b$$

```python
def linreg(X, w, b):  # 线性回归模型  
    return torch.matmul(X, w) + b
```

### 3.1.2.5 定义损失参数

- 用于梯度计算

```python
def squared_loss(y_hat, y):  # 均方损失函数  
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2  # 对应元素的平方 除以 2 未求均值
```

### 3.1.2.6 定义优化算法

- 小批量随机梯度下降
    - 在每一步中，使用从数据集中随机抽取的一个小批量，然后根据参数计算损失的梯度
    - 接下来，朝着减少损失的方向更新我们的参数

```python
def sgd(params, lr, batch_size):  # 小批量随机梯度下降算法  
    with torch.no_grad():  # 在 torch.no_grad() 范围内，梯度不会被自动计算和累加 更新参数时不需要梯度计算  
        for param in params:
            param -= lr * param.grad / batch_size  # 由于损失函数未计算均值，所以这里除以 batch_size
            param.grad.zero_()  # 梯度清零
```

### 3.1.2.7 训练

- 在每次迭代中，读取一小批量训练样本，并通模型来获得一组预测。
- 计算损失
- 反向传播，存储每个参数的梯度
- 调用优化算法`sgd`来更新模型参数

```python
lr = 0.03  # 学习率  
num_epochs = 3  # 迭代次数  
# 方便替换  
net = linreg  # 选择模型  
loss = squared_loss  # 选择损失函数  

for epoch in range(num_epochs):
    for X, y in data_iter(batch_size, features, labels):
        l = loss(net(X, w, b), y)  # 模型预测 计算损失  
        # 因为l形状是(batch_size,1)，而不是一个标量  
        # 需要调用.sum()函数来得到一个标量，并以此计算关于[w,b]的梯度  
        l.sum().backward()  # 求梯度  
        sgd([w, b], lr, batch_size)  # 使用小批量随机梯度下降迭代模型参数  
    with torch.no_grad():  # 在 torch.no_grad() 范围内，梯度不会被自动计算和累加  
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')  # 打印训练损失 mean()求均值  
# epoch 1, loss 0.037162  
# epoch 2, loss 0.000134  
# epoch 3, loss 0.000051
```

- 通过比较真实参数和通过训练学到的参数来评估训练的成功程度

```python
print(f'w: {true_w}, b: {true_b}')  # 打印真实参数  
print(f'w: {w.reshape((1, -1)), b}')  # 打印训练得到的参数  
print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')
print(f'b的估计误差: {true_b - b}')
# w: tensor([ 2.0000, -3.4000]), b: 4.2  
# w: (tensor([[ 1.9995, -3.3994]], grad_fn=<ViewBackward0>), tensor([4.1999], requires_grad=True))
```

- 通常不太关心恢复真正的参数，而更关心如何高度准确预测参数

## 3.1.4 线性回归的简洁实现

- 使用成熟的开源框架

### 生成数据集

```python
import numpy as np
import torch
from torch.utils import data
from d2l import torch as d2l

# 生成数据集  
true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = d2l.synthetic_data(true_w, true_b, 1000)  # 1000个样本
```

### 读取数据集

```python
# 读取数据集  
def load_array(data_arrays, batch_size, is_train=True):  # 布尔值is_train表示是否希望数据迭代器对象在每个迭代周期内打乱数据  
    """构造一个PyTorch数据迭代器"""
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)


batch_size = 10
data_iter = load_array((features, labels), batch_size)  # 返回的数据的迭代器  
print(next(iter(data_iter)))  # iter(data_iter) 是一个迭代器对象，next是取迭代器里面的元素  
# [tensor([[ 0.8482,  1.9892],  
#         [-0.5166, -1.1064],  
#         [ 2.2390,  0.2100],  
#         [ 0.5310,  1.0847],  
#         [-1.2754, -0.4711],  
#         [ 1.4253, -0.9882],  
#         [-2.3966,  0.4667],  
#         [ 0.6666, -2.1511],  
#         [-0.6097, -0.6963],  
#         [-0.3293,  0.1273]]),
# tensor([[-0.8530],  
#         [ 6.9264],  
#         [ 7.9642],  
#         [ 1.5826],  
#         [ 3.2568],  
#         [10.4177],  
#         [-2.1703],  
#         [12.8406],  
#         [ 5.3467],  
#         [ 3.1034]])]
```

### 定义模型

- 如果模型变得更加复杂，且当几乎每天都需要实现模型时，自然会想简化这个过程
- 对于标准深度学习模型，可以使用框架的预定义好的层。这使只需关注使用哪些层来构造模型，而不必关注层的实现细节
- 首先定义一个模型变量`net`，它是一个`Sequential`类的实例。`Sequential`类将多个层串联在一起。 当给定输入数据时，`Sequential`
  实例将数据传入到第一层， 然后将第一层的输出作为第二层的输入，以此类推
- 在PyTorch中，全连接层在`Linear`类中定义
- `Sequential`一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行， 同时以神经网络模块为元素的有序字典也可以作为传入参数。

```python
# nn是神经网络的缩写  
from torch import nn

net = nn.Sequential(nn.Linear(2, 1))  # 输入特征维度为2，输出维度为1
```

### 初始化模型参数

- 在使用`net`之前，需要初始化模型参数。 如在线性回归模型中的权重和偏置
- 正如我们在构造`nn.Linear`时指定输入和输出尺寸一样， 能直接访问参数以设定它们的初始值。 通过`net[0]`选择网络中的第一个图层，
  然后使用`weight.data`和`bias.data`方法访问参数。 还可以使用替换方法`normal_`和`fill_`来重写参数值

```python
net[0].weight.data.normal_(0, 0.01)  # 权重参数初始化 0均值，0.01标准差  
print(net[0].bias.data.fill_(0))  # 偏置参数初始化为0  
# tensor([0.])
```

### 定义损失函数

- 计算均方误差使用的是MSELoss类，也称为平方L2范数
- 默认情况下，它返回所有样本损失的平均值

```python
loss = nn.MSELoss()
```

### 定义优化算法

- PyTorch在`optim`模块中实现了小批量随机梯度下降算法的许多变种
- 当我们实例化一个`SGD`实例时，要指定优化的参数 （可通过`net.parameters()`从我们的模型中获得）以及优化算法所需的超参数字典
- 小批量随机梯度下降只需要设置`lr`值，这里设置为0.03

```python
trainer = torch.optim.SGD(net.parameters(), lr=0.03)  # 随机梯度下降优化算法
```

### 训练

- 在每个迭代周期里，我们将完整遍历一次数据集（`train_data`）， 不停地从中获取一个小批量的输入和相应的标签
- 对于每一个小批量，会进行以下步骤：
    - 通过调用`net(X)`生成预测并计算损失`loss`（前向传播）
    - 通过进行反向传播来计算梯度
    - 通过调用优化器来更新模型参数
- 为了更好的衡量训练效果，计算每个迭代周期后的损失，并打印它来监控训练过程

```python
num_epochs = 3
for epoch in range(num_epochs):
    for X, y in data_iter:
        l = loss(net(X), y)  # 计算损失  
        trainer.zero_grad()  # 梯度清零  
        l.backward()  # 反向传播  
        trainer.step()  # 更新参数  
    l = loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {l:f}')
# epoch 1, loss 0.000208  
# epoch 2, loss 0.000100  
# epoch 3, loss 0.000101
```

- 比较生成数据集的真实参数和通过有限数据训练获得的模型参数
- 要访问参数，首先从`net`访问所需的层，然后读取该层的权重和偏置

```python
w = net[0].weight.data
b = net[0].bias.data
print(f'w: {w.numpy()}, b: {b.numpy()}')  # numpy()方法用于转换为numpy数组  
# w: [[ 2.0004933 -3.399767 ]], b: [4.1998973]
```

# 3.2、Softmax 回归

- 虽然名字带有回归，但其实是一个分类问题
- 回归估计一个连续值：房价
- 分类预测一个离散类别：猫狗？（分两类）
- 通过单个仿射变换将我们的输入直接映射到输出，然后进行softmax操作

## 3.2.1 从回归到多类分类

- ![[00 Attachments/Pasted image 20240514191639.png|500]]
    - $$\begin{split}\begin{aligned}
      o_1 &= x_1 w_{11} + x_2 w_{12} + x_3 w_{13} + x_4 w_{14} + b_1,\\
      o_2 &= x_1 w_{21} + x_2 w_{22} + x_3 w_{23} + x_4 w_{24} + b_2,\\
      o_3 &= x_1 w_{31} + x_2 w_{32} + x_3 w_{33} + x_4 w_{34} + b_3.
      \end{aligned}\end{split}$$
    - $$\mathbf{o} = \mathbf{W} \mathbf{x} + \mathbf{b}$$
- 此时的 o 未进行任何规范化

### 均方损失

- ![[00 Attachments/Pasted image 20240514192936.png|500]]
    - 优化参数以最大化观测数据 $O_i$ 的概率：
        - 即输入类别为 i 则，对应的 $O_i$ 应为最大
        - 希望模型的输出 $𝑦^𝑗$ 可以视为属于类 $𝑗$ 的概率， 然后选择具有最大输出值的类别 $argma x_𝑗𝑦_𝑗$ 作为我们的预测
- 对类别进行独热编码（one-hot）
    - 独热编码是一个向量，它的分量和类别一样多。 类别对应的分量设置为1，其他所有分量设置为0
    - $$y \in \{(1, 0, 0), (0, 1, 0), (0, 0, 1)\}$$
- 整个数据集 $\{\mathbf{X}, \mathbf{Y}\}$ 具有 $𝑛$ 个样本， 其中索引 $𝑖$ 的样本由特征向量 $𝑥(𝑖)$ 和独热标签向量 $𝑦(𝑖)$ 组成

### 无校验比例

- 作为分类而言并不关心数值，而是是否能尽可能提高正确类别的置信度
- 要确保正确输入类 y 它对应的置信度 $O_y$ 要远远大于其他非 y 的对应置信度（大于等于某个阈值）
    - $$O_y - O_i \ge \Delta (y, i)$$
    - 这里关注的是相对值（而非具体的值），但如果进行归一化（放于合适的区间）处理会有助于判断
- ![[00 Attachments/Pasted image 20240514193848.png|500]]

### 校验比例

- 未规范化的预测 𝑜 不能直接视作感兴趣的输出
- 希望输出是一个概率（非负，和为一）
- 从而引入
  softmax函数：够将未规范化的预测变换为非负数并且总和为1，同时让模型保持可导的性质![[00 Attachments/Pasted image 20240514195002.png|500]]
    - 对 $O_i$ 做指数运算，确保非负；除以指数之和，归一化（和为1）
    - softmax 函数给出了一个向量 $\hat 𝑦$， 可以将其视为“对给定任意输入 𝑥 的每个类的条件概率”
        - $$\hat y_1 = P(y=\text{猫} \mid \mathbf{x})$$

### 交叉熵损失

- CrossEntropyLoss
  是一种常用的损失函数，主要用于分类问题，尤其是在多类分类任务中。它衡量了模型预测的概率分布与真实标签之间的差异，通过计算预测概率的对数与真实标签的交叉熵来评估模型性能。该损失函数鼓励模型将真实类别的概率推向
  1，而将其他类别的概率推向 0，因此在训练深度学习模型时，CrossEntropyLoss 能有效提高分类准确性。
- [“交叉熵”如何做损失函数？打包理解“信息量”、“比特”、“熵”、“KL散度”、“交叉熵”_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV15V411W7VB/?spm_id_from=333.337.search-card.all.click&vd_source=6fde3ed6da8858e6f7b2f1cc620c6173)
- 使用交叉熵衡量 $\hat y$ 与 $y$ （两个概率）的区别![[00 Attachments/Pasted image 20240514195744.png|500]]
    - 将 softmax 函数代入$$\begin{split}\begin{aligned}
      l(\mathbf{y}, \hat{\mathbf{y}}) &= - \sum_{j=1}^q y_j \log \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} \\
      &= \sum_{j=1}^q y_j \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j\\
      &= \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j
      \end{aligned}\end{split}$$
    - 关于 $o_j$
      求偏导$$\partial_{o_j} l(\mathbf{y}, \hat{\mathbf{y}}) = \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} - y_j = \mathrm{softmax}(\mathbf{o})_j - y_j$$
    - 由于 $𝑦$ 是独热编码向量（只有一个为 1，其他为 0），做乘积和后，除了一个项以外的所有项 i 都消失了

### 信息论基础

- 从新审视交叉熵

## 损失函数

- 拟合过程中，最小化损失函数，即为最大化似然函数

### 均方损失

- 假设 $y = 0$![[00 Attachments/Pasted image 20240514215400.png|400]]
    - 蓝线为 $l$，绿线为 对应的似然函数（表示 $\hat y = y$ 的可行性），橙线为梯度
    - 当 $\hat y$  与 $y = 0$ 离得较远时，梯度大，参数更新跨度较大（可能会带来不稳定），$\hat y$ 会朝箭头方向移动
    - 随着预测值逐渐靠近实际值，梯度减小，参数更新的跨度也变小

### 绝对值损失

- 上述，当估计值离得预测值较远时，参数更新跨度过大，为了缓解，可以采用绝对值损失
- 假设 $y = 0$![[00 Attachments/Pasted image 20240514221745.png|400]]
    - 可以知道，无论估计值离实际值有多远，参数更新跨度相同，可能会带来稳定性上的好处
    - 坏处，当 $\hat y$ 离 $y$ 很近时（优化到默契），梯度不稳定，可能会导致系统不稳定

### Huber's Robust Loss

- 结合均方损失与绝对值损失的优点
- ![[00 Attachments/Pasted image 20240514222122.png|400]]
    - 当预测值与实际值差的较大是，为绝对值损失；差的较小时，为均方损失（保证参数更新的平滑性）

## 图片分类数据集

- MNIST数据集是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。 我们将使用类似但更复杂的Fashion-MNIST数据集

```python
import torch
import torchvision
from torch.utils import data  # 导入数据集  
from torchvision import transforms  # 导入数据预处理  
from d2l import torch as d2l
```

### 读取数据集

- 通过框架中的内置函数将Fashion-MNIST数据集下载并读取到内存中
- 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，并除以255使得所有像素的数值均在0～1之间

```python
trans = transforms.ToTensor()  # 转换为张量  
# 训练集 train=True下载训练集，transform=trans得到的是pytorch的tensor格式，download=True默认从网上下载  
# 如果本地已经有了就不用下载了  
mnist_train = torchvision.datasets.MNIST(
    root='./data', train=True, transform=trans, download=False)  # 训练集  
mnist_test = torchvision.datasets.MNIST(
    root='./data', train=False, transform=trans, download=False)  # 测试集 用于验证模型的好坏
```

- Fashion-MNIST 由10个类别的图像组成， 每个类别由训练数据集（train dataset）中的6000张图像 和测试数据集（test
  dataset）中的1000张图像组成。 因此，训练集和测试集分别包含60000和10000张图像。 测试数据集不会用于训练，只用于评估模型性能。

```python
print(len(mnist_train), len(mnist_test))
# 60000 10000
```

- 每个输入图像的高度和宽度均为 28 像素。 数据集由灰度图像组成，其通道数为 1。 为了简洁起见，将高度 ℎ 像素、宽度 𝑤
  像素图像的形状记为 $ℎ×𝑤$ 或 $(ℎ,𝑤)$

```python
print(len(mnist_train), len(mnist_test))
# 60000 10000  
print(mnist_train.data.shape, mnist_test.data.shape)
# torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])  
print(mnist_train[0][0].shape, mnist_train[0][1])  # 第一个样本的形状和标签  
# torch.Size([1, 28, 28]) 5
```

-

Fashion-MNIST中包含的10个类别，分别为t-shirt（T恤）、trouser（裤子）、pullover（套衫）、dress（连衣裙）、coat（外套）、sandal（凉鞋）、shirt（衬衫）、sneaker（运动鞋）、bag（包）和ankle
boot（短靴）。 以下函数用于在数字标签索引及其文本名称之间进行转换

```python
def get_fashion_mnist_labels(labels):  # @save  
    """返回Fashion-MNIST数据集的文本标签"""
    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
    return [text_labels[int(i)] for i in labels]


def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  # @save  
    """绘制图像列表"""
    figsize = (num_cols * scale, num_rows * scale)
    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)
    axes = axes.flatten()
    for i, (ax, img) in enumerate(zip(axes, imgs)):
        if torch.is_tensor(img):
            # 图片张量  
            ax.imshow(img.numpy())
        else:
            # PIL图片  
            ax.imshow(img)
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        if titles:
            ax.set_title(titles[i])
    return axes


X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))  # 取出一组样本  
show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y))  # 绘制图像列表
```

- 画出的图像 ![[00 Attachments/Figure_2.png|500]]

### 读取小批量

- 为了使我们在读取训练集和测试集时更容易，我们使用内置的数据迭代器，而不是从零开始创建。 回顾一下，在每次迭代中，数据加载器每次都会读取一小批量数据，大小为
  `batch_size`。 通过内置数据迭代器，我们可以随机打乱了所有样本，从而无偏见地读取小批量

```python
batch_size = 256


def get_dataloader_workers():  # @save  
    """使用4个进程来读取数据"""
    return 4


train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,  # True表示每个epoch打乱数据  
                             num_workers=get_dataloader_workers()
                             if sys.platform.startswith('win64') else 0)  # windows下num_workers>0可能会报错
```

- 查看看读取训练数据所需的时间

```python
timer = d2l.Timer()
for X, y in train_iter:
    continue
print(f'{timer.stop():.2f} sec')
# 4.53 sec
```

### 整合所有组件

- 现在我们定义`load_data_fashion_mnist`函数，用于获取和读取 Fashion-MNIST 数据集
    - 这个函数返回训练集和验证集的数据迭代器
    - 此外，这个函数还接受一个可选参数`resize`，用来将图像大小调整为另一种形状。

```python
def load_data_fashion_mnist(batch_size, resize=None):  # @save  # resize=None表示不改变图像大小  
    """下载Fashion-MNIST数据集，然后将其加载到内存中"""
    trans = [transforms.ToTensor()]  # 定义图像转换操作  
    if resize:
        trans.insert(0, transforms.Resize(resize))  # 如果resize不为None，则在图像转换操作中插入Resize操作  
    trans = transforms.Compose(trans)  # 组合图像转换操作  
    mnist_train = torchvision.datasets.FashionMNIST(  # 下载Fashion-MNIST训练数据集  
        root="../data", train=True, transform=trans, download=True)
    mnist_test = torchvision.datasets.FashionMNIST(  # 下载Fashion-MNIST测试数据集  
        root="../data", train=False, transform=trans, download=True)
    return (data.DataLoader(mnist_train, batch_size, shuffle=True,  # 返回训练数据集和测试数据集的数据加载器  
                            num_workers=get_dataloader_workers()
                            if sys.platform.startswith('win64') else 0),
            data.DataLoader(mnist_test, batch_size, shuffle=False,
                            num_workers=get_dataloader_workers()
                            if sys.platform.startswith('win64') else 0))
```

- 通过指定`resize`参数来测试`load_data_fashion_mnist`函数的图像大小调整功能

```python
train_iter, test_iter = load_data_fashion_mnist(32, resize=64)
for X, y in train_iter:
    print(X.shape, X.dtype, y.shape, y.dtype)
    break
# torch.Size([32, 1, 64, 64]) torch.float32 torch.Size([32]) torch.int64
```

## Softmax 从零开始

```python
import torch
from IPython import display
from d2l import torch as d2l

bath_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=bath_size)  # 在源代码处加入了操作系统的判断
```

### 初始化模型参数

- 在之前的线性回归中，样本是由固定长度的向量表示的
- 此处，原始样本为 28\*28 的图像，将其展开为长度为 784 的向量，将每个像素位置视作一个特征（之后将讨论能投利用图像空间结构的特征）
- 在 softmsx 中，输出个数与数据集类别个数相同。因为数据集有10个类别，所以网络输出维度为10
- 因此权重将构成一个 784×10 的矩阵， 偏置将构成一个 1×10 的行向量
- 使用正态分布初始化 w，偏执初始化为 0

```python
num_inputs = 784
num_outputs = 10

W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)
b = torch.zeros(num_outputs, requires_grad=True)
```

### 定义 softmax 操作

- $$\mathrm{softmax}(\mathbf{X})_{ij} = \frac{\exp(\mathbf{X}_{ij})}{\sum_k \exp(\mathbf{X}_{ik})}$$
- softmax 有三步
    - 对每个项求幂
    - 对每一行求和（小批量中，每个样本是一样），得到每个样本的规范化常数
    - 将每一行除以其规范化常数，确保结果的和为1

```python
def softmax(X):
    """输入的 X 是一组预测值，输出 softmax 处理过的预测值"""
    X_exp = torch.exp(X)
    partition = X_exp.sum(dim=1, keepdim=True)
    return X_exp / partition  # 应用了广播机制
```

- 对于任何随即输入，将每个元素变成一个非负数。且每行综合为 1
- 举例

```python
X = torch.normal(0, 1, (2, 5))
X_prob = softmax(X)
print(X_prob)
# tensor([[0.1227, 0.2125, 0.2198, 0.1211, 0.3239],  
#         [0.3685, 0.1344, 0.1431, 0.2738, 0.0803]])
```

### 定义模型

- 定义 softmax 后，我们可以实现 softmax 回归模型
- 下面的代码定义了输入如何通过网络映射到输出

```python
def net(X):
    """输入的 X 是图像数据，输出预测值"""
    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)  # 使用reshape函数将每张原始图像展平为向量
```

### 定义损失函数

- 交叉熵采用真实标签的预测概率的负对数似然

```python
def cross_entropy(y_hat, y):
    """输入的 y_hat 是预测值，y 是真实标签，输出交叉熵损失"""
    return -torch.log(y_hat[range(len(y_hat)), y])  # 由于独热编码，只需计算实际标签对应的预测值的对数即可
```

- 由于独热编码，这里至于要知道实际类别对应的预测值即可，但如何将实际值对应的预测值取出？
    - 这里不使用 Python 的 for 循环迭代预测（这往往是低效的）， 而是通过一个运算符选择所有元素
    - 下面创建一个数据样本 $\hat y$，其中包含 2 个样本在 3 个类别的预测，以及它们对应的标签
    - 有了`y`，可以知道在第 0 个样本中，第 0 类是正确的预测； 而在第 1 个样本中，第 2 类是正确的预测。 然后使用 `y` 作为
      `y_hat` 中概率的索引， 选择第一个样本中第 0 个类的概率和第二个样本中第 2 个类的概率

```python
y = torch.tensor([0, 2])  # 实际标签  
y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])  # 预测值  
print(y_hat[[0, 1], y])  # 输出  
# tensor([0.1000, 0.5000])  
print(cross_entropy(y_hat, y))
# tensor([2.3026, 0.6931])
```

### 分类精度

- 给定预测概率分布`y_hat`，当我们必须输出硬预测（hard prediction）时， 我们通常选择预测概率最高的类（做出选择）
- 当预测与标签分类`y`一致时，即是正确的。 ==分类精度==即正确预测数量与总预测数量之比
    - 虽然直接优化精度可能很困难（因为精度的计算不可导）， 但精度通常是我们最关心的性能衡量标准，我们在训练分类器时几乎总会关注它
- 计算精度
    1. 如果`y_hat`是矩阵，那么假定第二个维度存储每个类的预测分数
    2. 使用`argmax`获得每行中最大元素的索引来获得预测类别
    3. 将预测类别与真实`y`元素进行比较（由于等式运算符“`==`”对数据类型很敏感， 因此我们将`y_hat`的数据类型转换为与`y`
       的数据类型一致）（结果是一个包含0（错）和1（对）的张量）
    4. 求和得到正确预测的数量

```python
def accuracy(y_hat, y):
    """输入的 y_hat 是预测值，y 是真实标签，输出预算值与实际一致的个数"""


if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:  # y_hat 为矩阵，y_hat.shape[1]>1表示不止一个类别，每个类别有各自的概率  
    # print("y_hat_before", y_hat)  
    # # y_hat_before tensor([[0.1000, 0.3000, 0.6000],
    # #         [0.3000, 0.2000, 0.5000]])
    y_hat = y_hat.argmax(axis=1)  # y_hat.argmax(axis=1)为求行最大值索引 axis=1表示按列求最大值  
    # print("y_hat_after", y_hat)  
    # # y_hat_after tensor([2, 2])
    cmp = y_hat.type(y.dtype) == y  # 先判断逻辑运算符==，再赋值给cmp，cmp为布尔类型的数据 type 函数用于转换数据类型  
return float(cmp.type(y.dtype).sum())  # 获得y.dtype的类型作为传入参数，将cmp的类型转为y的类型（int型），然后再求和  
```

- 继续使用之前定义的变量`y_hat`和`y`分别作为预测的概率分布和标签
- 可以看到，第 0 个样本的预测类别是 2（该行的最大元素为0.6，索引为2），这与实际标签 0 不一致。 第 1
  个样本的预测类别是2（该行的最大元素为0.5，索引为2），这与实际标签 2 一致。 因此，这两个样本的分类精度率为0.5

```python
print("accuracy(y_hat,y) / len(y):", accuracy(y_hat, y) / len(y))
print("accuracy(y_hat,y):", accuracy(y_hat, y))  # 预测与实际一致的个数  
print("len(y):", len(y))
# accuracy(y_hat,y) / len(y): 0.5  
# accuracy(y_hat,y): 1.0  
# len(y): 2
```

- 对于任意数据迭代器`data_iter`可访问的数据集， 我们可以评估在任意模型`net`的精度

```python
def evaluate_accuracy(net, data_iter):
    """计算在指定数据集上模型的精度"""
    if isinstance(net, torch.nn.Module):  # 如果net模型是torch.nn.Module实现的神经网络的话，将它变成评估模式  
        net.eval()  # 将模型设置为评估模式  
    metric = Accumulator(2)  # 正确预测数、预测总数，metric为累加器的实例化对象，里面存了两个数  
    for X, y in data_iter:
        metric.add(accuracy(net(X), y), y.numel())  # net(X)将X输入模型，获得预测值。y.numel()为样本总数  
    return metric[0] / metric[1]  # 分类正确的样本数 / 总样本数
```

- 定义一个实用程序类`Accumulator`，用于对多个变量进行累加
    - 在上面的`evaluate_accuracy`函数中， 我们在`Accumulator`实例中创建了2个变量， 分别用于存储正确预测的数量和预测的总数量。
      当我们遍历数据集时，两者都将随着时间的推移而累加

```python
# Accumulator实例中创建了2个变量，用于分别存储正确预测的数量和预测的总数量  
class Accumulator:
    """在n个变量上累加"""

    def __init__(self, n):
        self.data = [0, 0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]  # zip函数把两个列表第一个位置元素打包、第二个位置元素打包....  

    def reset(self):
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]
```

- 随机权重和偏置初始化 net 模型，则该模型的精度是随机的

```python
print(evaluate_accuracy(net, test_iter))  # 输出模型在测试集上的精度  
# 0.0994
```

### 训练

- 定义一个函数来训练一个迭代周期
- `updater`是更新模型参数的常用函数，它接受批量大小作为参数

```python
def train_epoch_ch3(net, train_iter, loss, updater):  # @save  
    """训练模型一个迭代周期（定义见第3章）"""
    if isinstance(net, torch.nn.Module):  # 如果net模型是torch.nn.Module实现的神经网络的话，将它变成训练模式  
        net.train()
    # 训练损失总和、训练准确度总和、样本数  
    metric = Accumulator(3)
    for X, y in train_iter:
        # 计算梯度并更新参数  
        y_hat = net(X)
        l = loss(y_hat, y)
        if isinstance(updater, torch.optim.Optimizer):  # 如果updater是torch.optim.Optimizer实例的话，使用PyTorch内置的优化器和损失函数  
            # 使用PyTorch内置的优化器和损失函数  
            updater.zero_grad()  # 梯度清零  
            l.mean().backward()  # 计算梯度  
            updater.step()  # 更新参数  
        else:
            # 使用定制的优化器和损失函数  
            l.sum().backward()
            updater(X.shape[0])
        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())
    # 返回训练损失和训练精度  
    return metric[0] / metric[2], metric[1] / metric[2]
```

- 展示训练函数的实现之前，定义一个在动画中绘制数据的实用程序类`Animator`， 它能够简化本书其余部分的代码
    - 适配pycharm

```python
class Animator:
    """在动画中绘制数据"""

    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,
                 ylim=None, xscale='linear', yscale='linear',
                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,
                 figsize=(3.5, 2.5)):
        """  
        初始化Animator对象  
  
        参数:  
        - xlabel: x轴标签  
        - ylabel: y轴标签  
        - legend: 图例  
        - xlim: x轴范围  
        - ylim: y轴范围  
        - xscale: x轴比例  
        - yscale: y轴比例  
        - fmts: 线条格式  
        - nrows: 子图行数  
        - ncols: 子图列数  
        - figsize: 图表大小  
        """
        if legend is None:
            legend = []
        # 使用SVG显示动画  
        d2l.use_svg_display()
        # 创建包含多个子图的图表  
        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)
        # 如果只有一个子图，则将其放入列表中，方便后续处理  
        if nrows * ncols == 1:
            self.axes = [self.axes]
        # 使用lambda函数配置坐标轴  
        self.config_axes = lambda: d2l.set_axes(
            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)
        # 初始化X和Y坐标以及线条格式  
        self.X, self.Y, self.fmts = None, None, fmts

    def add(self, x, y):
        """  
        向图表中添加多个数据点  
  
        参数:  
        - x: x坐标数据  
        - y: y坐标数据  
        """  # 如果y不是列表或数组，将其转换为列表  
        if not hasattr(y, "__len__"):
            y = [y]
        n = len(y)
        # 如果x不是列表或数组，将其转换为与y相同长度的列表  
        if not hasattr(x, "__len__"):
            x = [x] * n
        # 如果X和Y坐标为空，则初始化它们  
        if not self.X:
            self.X = [[] for _ in range(n)]
        if not self.Y:
            self.Y = [[] for _ in range(n)]
        # 将数据添加到X和Y坐标中  
        for i, (a, b) in enumerate(zip(x, y)):
            if a is not None and b is not None:
                self.X[i].append(a)
                self.Y[i].append(b)
            # 清空图表并绘制线条  
        self.axes[0].cla()
        for x, y, fmt in zip(self.X, self.Y, self.fmts):
            self.axes[0].plot(x, y, fmt)
        # 配置坐标轴并显示图表  
        self.config_axes()
        d2l.plt.draw()  # 更新图表  
        d2l.plt.pause(0.001)  # 短暂暂停以更新图表
```

- 实现一个训练函数， 它会在`train_iter`访问到的训练数据集上训练一个模型`net`。
- 该训练函数将会运行多个迭代周期（由`num_epochs`指定）。 在每个迭代周期结束时，利用`test_iter`访问到的测试数据集对模型进行评估。
- 利用`Animator`类来可视化训练进度

```python
def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  # @save  
    """训练模型（定义见第3章）"""
    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],
                        legend=['train_loss', 'train_acc', 'test_acc'])  # 绘制动画  
    for epoch in range(num_epochs):  # 训练num_epochs个迭代周期  
        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)  # 训练一个迭代周期  
        test_acc = evaluate_accuracy(net, test_iter)  # 在测试集上评估模型  
        animator.add(epoch + 1, train_metrics + (test_acc,))  # 向动画中添加数据  
        train_loss, train_acc = train_metrics
        print(f'num_epochs {epoch + 1}, train_loss {train_loss:.3f}, train_acc {train_acc:.3f}')
        # num_epochs 1, train_loss 0.786, train_acc 0.751  
        # num_epochs 2, train_loss 0.569, train_acc 0.813        
        # num_epochs 3, train_loss 0.524, train_acc 0.826        
        # num_epochs 4, train_loss 0.500, train_acc 0.833        
        # num_epochs 5, train_loss 0.486, train_acc 0.836        
        # num_epochs 6, train_loss 0.474, train_acc 0.840        
        # num_epochs 7, train_loss 0.465, train_acc 0.842        
        # num_epochs 8, train_loss 0.458, train_acc 0.846        
        # num_epochs 9, train_loss 0.453, train_acc 0.847        
        # num_epochs 10, train_loss 0.446, train_acc 0.849    
        assert train_loss < 0.5, train_loss  # 训练损失不应超过0.5  
    assert train_acc <= 1 and train_acc > 0.7, train_acc  # 训练精度应介于0.7和1之间  
    assert test_acc <= 1 and test_acc > 0.7, test_acc  # 测试精度应介于0.7和1之间
```

- 优化算法，小批量梯度下降

```python
lr = 0.1  # 学习率  


# 优化函数  
def updater(batch_size):
    return d2l.sgd([W, b], lr, batch_size)  # 使用小批量随机梯度下降
```

- 训练模型10个迭代周期
    - 迭代周期（`num_epochs`）和学习率（`lr`）都是可调节的超参数。 通过更改它们的值，我们可以提高模型的分类精度

```python
num_epochs = 10
train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)
```

- ![[00 Attachments/Figure_3.png|400]]

### 预测

- 训练已经完成，已经准备好对图像进行分类预测。
    - 给定一系列图像，比较它们的实际标签（文本输出的第一行）和模型预测（文本输出的第二行）

```python
def predict_ch3(net, test_iter, n=10):  # @save  
    """预测标签（定义见第3章）"""
    for X, y in test_iter:  # 测试数据集  
        break
    trues = d2l.get_fashion_mnist_labels(y)  # 获得真实标签  
    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))  # 获得预测标签  
    titles = [true + '\n' + pred for true, pred in zip(trues, preds)]
    d2l.show_images(
        X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])


predict_ch3(net, test_iter)
```

- ![[00 Attachments/Figure_4.png]]

## Softmax 回归简洁算法

```python
import torch
from torch import nn
from d2l import torch as d2l

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
```

#### 初始化模型参数

- softmax回归的输出层是一个全连接层。 因此，为了实现我们的模型， 我们只需在`Sequential`中添加一个带有10个输出的全连接层。
    - 同样，在这里`Sequential`并不是必要的， 但它是实现深度模型的基础
- 我们仍然以均值0和标准差0.01随机初始化权重

```python
# 初始化模型参数  
# PyTorch不会隐式地调整输入的形状。因此，  
# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状 保存第 0 维 其他维度展成 1 维张量
net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))  # sequential 将多个层组合成一个网络 flattern将输入数据展平 


def init_weights(m):
    if type(m) == nn.Linear:  # 判断 m 是否为线性层  
        nn.init.normal_(m.weight, std=0.01)  # 使用正态分布初始化权重  


net.apply(init_weights)  # 应用初始化函数
```

#### 重新审视 Softmax 的实现

- 在上节中，计算了模型的输出，然后将输出送入交叉熵损失。从数学上将，这是一件完全合理的事情
- 然而，从计算角度看，指数可能会造成数值稳定性问题（溢出）
    - $$\hat y_j = \frac{\exp(o_j)}{\sum_k \exp(o_k)}$$
- 在计算 softmax 之前，先从所有的 $O_k$ 中减去 $max(O_k)$。
    - 提出最大项$$\begin{split}\begin{aligned}
      \hat y_j & = \frac{\exp(o_j - \max(o_k))\exp(\max(o_k))}{\sum_k \exp(o_k - \max(o_k))\exp(\max(o_k))} \\
      & = \frac{\exp(o_j - \max(o_k))}{\sum_k \exp(o_k - \max(o_k))}.
      \end{aligned}\end{split}$$
- 在减法和规范化步骤之后，可能有些 $𝑜_𝑗−max(𝑜_𝑘)$ 具有较大的负值（导致指数运算溢出）
- 尽管我们要计算指数函数，但我们最终在计算交叉熵损失时会取它们的对数
- 求对数以抵消求指数$$\begin{split}\begin{aligned}
  \log{(\hat y_j)} & = \log\left( \frac{\exp(o_j - \max(o_k))}{\sum_k \exp(o_k - \max(o_k))}\right) \\
  & = \log{(\exp(o_j - \max(o_k)))}-\log{\left( \sum_k \exp(o_k - \max(o_k)) \right)} \\
  & = o_j - \max(o_k) -\log{\left( \sum_k \exp(o_k - \max(o_k)) \right)}.
  \end{aligned}\end{split}$$
- 希望保留传统的 softmax 函数，以备我们需要评估通过模型输出的概率。 但是，我们没有将 softmax 概率传递到损失函数中，
  而是直接在交叉熵损失函数中传递未规范化的预测，并同时计算 softmax 及其对数

```python
loss = nn.CrossEntropyLoss(reduction='none')
```

#### 优化算法

```python
trainer = torch.optim.SGD(net.parameters(), lr=0.1)
```

#### 训练

```python
num_epochs = 10
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```

- ![[00 Attachments/Figure_5.png]]
  ;

# 3.3、多层感知机（MLP）

## 3.3.1、单层感知机

### 单层感知机

- 通过放射函数将输入映射到输出，然后加入一个激活函数![[00 Attachments/Pasted image 20240516153736.png|500]]
- 激活函数可自定义![[00 Attachments/Pasted image 20240516154324.png|500]]
    - 相较于线性回归：线性回归输出为实数；而感知机输出为离散的类
    - 相较于 softmax：softmax 如果有 n 个类，就会输出 n 个元素（对应类的概率 ），是一个多分类的问题；而感知机只能进行二分类

### 训练感知机

- ![[00 Attachments/Pasted image 20240516211254.png|500]]
    - 如果分类正确的话 $y_i<w,x_i>$ 为正数，则损失为 0，则梯度不进行更新
    - 如果分类错误的话 $y_i<w,x_i>$ 为负数，则损失为 $-y_i<w,x_i>$，进行梯度更新
        - 学习率为 1，$y_ix_i$ 为梯度
    - 重复上述过程直至==所有分类正确==（停止条件）
-

模型更新示意图，黑线即可视为权重![[00 Attachments/Pasted image 20240516213531.png|200]]![[00 Attachments/Pasted image 20240516213550.png|200]]![[00 Attachments/Pasted image 20240516213613.png|200]]![[00 Attachments/Pasted image 20240516214332.png|200]]

### 收敛定理

- 停止条件，对所有的类都分类正确![[00 Attachments/Pasted image 20240516214634.png|500]]
    - 假设数据都在半径为 r 的一个区域内
    - 所有分类均分类正确，大于 0，且还保留一定余量 $y(\mathbf{X} ^T\mathbf{W} +b)\ge \rho$
      ，且保证在 $\left \| \mathbf{w} \right \|^2 +b^2 \le 1$ 之后收敛
    - $\rho$ 越大（宽松），则收敛的步数越少

### XOR 问题

- 异或（相同为 0，不同为 1）![[00 Attachments/Pasted image 20240516220625.png|500]]
    - 单层感知机不能很好的分类

### 总结

- ![[00 Attachments/Pasted image 20240516221057.png|500]]

## 3.3.2、多层感知机

- Multilayer Perceptron, MLP

### 学习XOR

-

先用蓝色的线分，再用黄色的线分。再对蓝色的线和黄色的线分出来的结果做同或![[00 Attachments/Pasted image 20240516221148.png|500]]

- 一层选择不了，就分多层

### 单层隐藏层

- ![[00 Attachments/Pasted image 20240516223159.png|500]]
    - 输入数据大小影响因素不可更改，输出个数由类别个数决定，但可以设置隐藏层的大小
- 这里只有一个输出![[00 Attachments/Pasted image 20240516224352.png|500]]
    - 问什么激活函数一定要非线性
        - 若激活函数为线性，则等价于单层线性模型 $o = \mathbf{w} _2^T\mathbf{W} _1\mathbf{x} +b^{'}$（线性函数与线性函数的复合依然为线性函数）

### 激活函数

- 由于阶跃函数非连续，不方便求导
- Sigmoid 函数![[00 Attachments/Pasted image 20240516225357.png|500]]
- Tanh 函数![[00 Attachments/Pasted image 20240516225445.png|500]]
- ReLU![[00 Attachments/Pasted image 20240516225500.png|500]]
    - ReLU的好处在于不需要执行指数运算（在CPU中，一次指数运算等价于100次乘法运算，在GPU中有特定的单元，但依然费时）

### 多类分类

- 没有隐藏层，即为 Softmax 回归；加了隐藏层，即为多层感知机![[00 Attachments/Pasted image 20240516231806.png|500]]
- 与之前单输出相比，输出层大小为类别个数![[00 Attachments/Pasted image 20240516232158.png|500]]
    - 对输出要进行一次 softmax，以符合概率条件

### 多隐藏层

- 隐藏层可以建得更多![[00 Attachments/Pasted image 20240516232418.png|500]]
    - 没有激活函数，会导致层数塌陷，变成单层感知机，不能解决 XOR 问题
    - 层数做深，为了使信息量逐层减少（一次压多了可能会减少很多信息）

### 总结

- 使用隐藏层和激活函数类的到非线性模型，解决了单层感知机不能解决 xor 的局限性
- 常用激活函数是 Sigmoid，Tanh，ReLU
    - ReLU 由于实现简单，从而更常用
- 使用 Softmax 来处理多类分类
    - 在 Softmax 回归中加入了 隐藏层
- 草参数为隐藏层数和各个隐藏层大小

## 3.3.3、多层感知的从零开始实现

- 为了与之前 softmax 回归获得的结果进行比较， 我们将继续使用 Fashion-MNIST 图像分类数据集

```python
import torch
from torch import nn
from d2l import torch as d2l

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
```

### 初始化模型参数

- Fashion-MNIST 中的每个图像由 28×28=784 个灰度像素值组成。所有图像共分为 10 个类别。 忽略像素之间的空间结构，
  可以将每个图像视为具有784个输入特征 和10个类的简单分类数据集
- 首先，将实现一个具有单隐藏层的多层感知机， 它包含 256 个隐藏单元。
    - 注意，可以将这两个变量都视为超参数。 通常，我们选择 2 的若干次幂作为层的宽度。 因为内存在硬件中的分配和寻址方式，这么做往往可以在计算上更高效
- 用几个张量来表示参数
    - 注意，对于每一层都要记录一个权重矩阵和一个偏置向量。 跟以前一样，我们要为损失关于这些参数的梯度分配内存
- 参数初始化为随机：如果是全部设置为0的话，每一个神经元的输出都是相同的，那不就是如同一个神经元了嘛，多个神经元的特性就没有了
- 设置为零的话梯度为0，参数不会更新，相当于隐藏层只有一个单元

```python
num_inputs, num_outputs, num_hiddens = 784, 10, 256  # num_inputs:输入特征数，num_outputs:输出特征数，num_hiddens:隐藏层特征数  

W1 = nn.Parameter(torch.randn(
    num_inputs, num_hiddens, requires_grad=True) * 0.01)  # 权重参数初始化 行数为输入特征数，列数为隐藏层特征数  
b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))  # 偏置参数初始化  
W2 = nn.Parameter(torch.randn(
    num_hiddens, num_outputs, requires_grad=True) * 0.01)  # 权重参数初始化 行数为隐藏层特征数，列数为输出特征数  
b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))  # 偏置参数初始化  

params = [W1, b1, W2, b2]  # 模型参数列表
```

### 实现 ReLU 激活函数

```python
def relu(X):
    a = torch.zeros_like(X)  # 新建一个全零张量，形状和 X 相同  
    return torch.max(X, a)  # 选择 X 和 全零张量中的最大值作为输出
```

### 实现模型

- 因为我们忽略了空间结构， 所以我们使用`reshape`将每个二维图像转换为一个长度为`num_inputs`的向量

```python
def net(X):
    X = X.reshape((-1, num_inputs))  # 将图像展平 改变 X 的形状为 (batch_size, num_inputs) 样本按行排列  
    H = relu(X @ W1 + b1)  # 隐藏层输出 X @ W1 等价于 torch.matmul(X, W1)    return H @ W2 + b2  # 输出层输出
```

### 损失函数

- 由于我们已经从零实现过 softmax 函数， 因此在这里我们直接使用高级API中的内置函数来计算softmax和交叉熵损失

```python
loss = nn.CrossEntropyLoss(reduction='none')  # reduction='none' 表示返回每个样本的损失值
```

### 训练

- 多层感知机的训练过程与 softmax 回归的训练过程完全相同。 可以直接调用`d2l`包的`train_ch3`函数，将迭代周期数设置为
  10，并将学习率设置为 0.1

```python
num_epochs, lr = 10, 0.1
updater = torch.optim.SGD(params, lr=lr)  # 优化器  
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)
```

- ![[00 Attachments/Figure_6.png|400]]
    - 与 Softmax 回归相比，损失往下降了，但精度好像没有明显的变化
- 测试

```python
d2l.predict_ch3(net, test_iter)
```

- ![[00 Attachments/Figure_7.png|400]]

## 3.3.4、多层感知机的简洁实现

- 与 softmax 回归的简洁实现相比， 唯一的区别是添加了 2 个全连接层（之前我们只添加了1个全连接层）
    - 第一层是隐藏层，它包含256个隐藏单元，并使用了ReLU激活函数
    - 第二层是输出层

```python
import torch
from torch import nn
from d2l import torch as d2l

# 初始化模型参数  
# PyTorch不会隐式地调整输入的形状。因此，  
# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状 保存第 0 维 其他维度展成 1 维张量  
net = nn.Sequential(nn.Flatten(),
                    nn.Linear(784, 256),
                    nn.ReLU(),
                    nn.Linear(256, 10))  # sequential 将多个层组合成一个网络 flattern将输入数据展平  


def init_weights(m):
    if type(m) == nn.Linear:  # 判断 m 是否为线性层  
        nn.init.normal_(m.weight, std=0.01)  # 使用正态分布初始化权重  


net.apply(init_weights)  # 应用初始化函数  

batch_size, lr, num_epochs = 256, 0.1, 10

# 定义交叉熵损失函数  
loss = nn.CrossEntropyLoss(reduction='none')  # 定义损失函数，reduction='none'表示返回每个样本的损失值  

# 定义优化算法  
trainer = torch.optim.SGD(net.parameters(), lr=lr)

# 加载数据集  
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)

# 训练模型  
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```

- ![[00 Attachments/Figure_8.png|400]]
